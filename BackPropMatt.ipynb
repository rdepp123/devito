{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lvG4ycQ_XfQD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdepp123/devito/blob/master/BackPropMatt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLiFRNh1CJER"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "#\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import losses\n",
        "from scipy.stats import norm\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, MeanSquaredError\n",
        "from tensorflow.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if we can reproduce the following model from Matt Mazur blog and check all gradients and weights ...:\n",
        "MODEL https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
        "\n",
        "Each output o1 and o2 is real between 0.0 and 1.0\n",
        "*   Learning rate : 0.5\n",
        "*   Loss : Mean Squarred Error\n",
        "*   Optimizer : Simple Gradient Descent\n",
        "*   Normalization : Sigmoid function\n",
        "*   Bias : not updatable\n"
      ],
      "metadata": {
        "id": "Jmmbvd-4ED_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![neural_network-9.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "YQvWNAITGYu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input_layer = Input(shape=(2,1))\n",
        "inputs = tf.constant([[0.05, 0.1]])"
      ],
      "metadata": {
        "id": "BbvNBKynG5gV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SetBias(tf.keras.constraints.Constraint):\n",
        "  \"\"\"Constrains bias 1 to be 0.35\"\"\"\n",
        "\n",
        "  def __init__(self, ref_value):\n",
        "    self.ref_value = ref_value\n",
        "\n",
        "  def __call__(self, bias):\n",
        "    bias_cst=tf.fill(bias.shape, self.ref_value)\n",
        "    return bias_cst"
      ],
      "metadata": {
        "id": "P47t1lqiyWXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some useful functions"
      ],
      "metadata": {
        "id": "lvG4ycQ_XfQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "def cross_entropy(y,y_pre):\n",
        "  loss=-np.sum(y*np.log(y_pre))\n",
        "  return loss/float(y_pre.shape[0])\n",
        "def logistic(x):\n",
        "  logistic=1/(1+np.exp(-x))\n",
        "  return logistic"
      ],
      "metadata": {
        "id": "3dAsTvHlXr9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "def cross_entropy(y,y_pre):\n",
        "  loss=-np.sum(y*np.log(y_pre))\n",
        "  return loss/float(y_pre.shape[0])\n",
        "def logistic(x):\n",
        "  logistic=1/(1+np.exp(-x))\n",
        "  return logistic"
      ],
      "metadata": {
        "id": "c7ohitE9h2pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([0.1, 0.9, 4.0])\n",
        "output=softmax(x)\n",
        "print('Softmax in Python :',output)"
      ],
      "metadata": {
        "id": "wlGi42OsXyWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([1.105905967, 1.224921404])\n",
        "output=logistic(x)\n",
        "print('logistics fn :',output)"
      ],
      "metadata": {
        "id": "yEbfyRHBXygf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=tf.keras.losses.MeanSquaredError()\n",
        "y_pred = [[0.751365066, 0.772928476]]\n",
        "y_true = [[0.01, 0.99]]\n",
        "\n",
        "loss = loss_fn( y_true,y_pred)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqSUpdv3iLuK",
        "outputId": "31e2ddb1-e85c-49ce-ce49-8d1fa922282a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.2983711>"
            ]
          },
          "metadata": {},
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Layer1 and check if it fits Matt model"
      ],
      "metadata": {
        "id": "mTe8Unad_KOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We set weights and biases according to Mattews example\n",
        "setBias1=SetBias(0.35)\n",
        "W1 = np.array([[0.15,0.25],[0.30,0.40]])\n",
        "b1 = np.array([0.35,0.35])\n",
        "dense_layer1 = layers.Dense(units=2,\n",
        "                            use_bias=True,\n",
        "                            bias_constraint=setBias1,\n",
        "                            weights = [W1,b1],\n",
        "                            activation=activations.sigmoid,\n",
        "                            name='layer1'\n",
        "                            )"
      ],
      "metadata": {
        "id": "b3C0rkz2-UBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that Layer 1 gives same result as Matt example"
      ],
      "metadata": {
        "id": "ohEXZg5kSqdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=dense_layer1(inputs)\n",
        "# In his blog Mattews indicate out h1=0.593269992, out h2=0.596884378\n",
        "out_h1=h[0][0]\n",
        "out_h2=h[0][1]\n",
        "#print('out h1= {0:.9f}'.format(h[0][0])+ '  out h2= {0:.9f}'.format(h[0][1]))\n",
        "matt_h1=0.593269992\n",
        "matt_h2=0.596884378\n",
        "diff_h1 = out_h1-matt_h1\n",
        "diff_h2 = out_h2-matt_h2\n",
        "print('Model out h1= {0:.9f}'.format(out_h1)+ ' Model out h2= {0:.9f}'.format(out_h2))\n",
        "print('Matt  out h1= {0:.9f}'.format(matt_h1)+ ' Matt  out h2= {0:.9f}'.format(matt_h2))\n",
        "#print('diff h1= {0:.9f}'.format(diff_h1)+ '  diff h2= {0:.9f}'.format(diff_h2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4gGMC8-Hjg0",
        "outputId": "5b4042b0-c599-4c42-99d8-59f43b69cbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model out h1= 0.595680773 Model out h2= 0.599288166\n",
            "Matt  out h1= 0.593269992 Matt  out h2= 0.596884378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create layer 2 and check if it fits Matt model\n",
        "\n",
        "1.   Élément de liste\n",
        "2.   Élément de liste\n",
        "\n"
      ],
      "metadata": {
        "id": "zjKKeZ9fS0_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We set weights and biases according to Matt example\n",
        "setBias2=SetBias(0.6)\n",
        "\n",
        "W2 = np.array([[0.4,0.5],[0.45,0.55]])\n",
        "b2 = np.array([0.6,0.6])\n",
        "dense_layer2 = layers.Dense(units=2,\n",
        "                            use_bias=True,\n",
        "                            bias_constraint=setBias2,\n",
        "                            weights = [W2,b2],\n",
        "                            activation=activations.sigmoid,\n",
        "                            name='layer2'\n",
        "                            )\n",
        "\n"
      ],
      "metadata": {
        "id": "dVSJd6X8MOqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that Layer 2 gives same results as Matt Example\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-XCpn1VpTHjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "o=dense_layer2(h)\n",
        "# In his blog Mattews indicate out o1=0.75136507, out o2=0.772928465\n",
        "out_o1=o[0][0]\n",
        "out_o2=o[0][1]\n",
        "#print('out o1= {0:.9f}'.format(o[0][0])+ '  out o2= {0:.9f}'.format(o[0][1]))\n",
        "matt_o1=0.75136507\n",
        "matt_o2=0.772928465\n",
        "diff_o1 = out_o1-matt_o1\n",
        "diff_o2 = out_o2-matt_o2\n",
        "print('Model out o1= {0:.9f}'.format(out_o1)+ ' Model out o2= {0:.9f}'.format(out_o2))\n",
        "print('Matt  out o1= {0:.9f}'.format(matt_o1)+ ' Matt  out o2= {0:.9f}'.format(matt_o2))\n",
        "#print('diff o1= {0:.9f}'.format(diff_o1)+ '  diff o2= {0:.9f}'.format(diff_o2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcVRQAKrS_Sd",
        "outputId": "be4e968c-be8e-4e68-973b-cb32f9820baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model out o1= 0.751747072 Model out o2= 0.773371816\n",
            "Matt  out o1= 0.751365070 Matt  out o2= 0.772928465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Matt Model :\n",
        "# Input => Layer1 => Layer 2"
      ],
      "metadata": {
        "id": "OJ7eridySMKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creation of the Matt model\n",
        "layer_inputs = Input(shape=(2,))\n",
        "out_layer1=dense_layer1(layer_inputs)\n",
        "out_layer2=dense_layer2(out_layer1)\n",
        "matt_model=Model(layer_inputs,out_layer2)\n",
        "matt_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wveY5XyWHj3y",
        "outputId": "b2a0e1da-6c30-4821-89d1-b7f83a24bdb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " layer1 (Dense)              (None, 2)                 6         \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 2)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12 (48.00 Byte)\n",
            "Trainable params: 12 (48.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test Matt model\n",
        "model_o=matt_model(inputs)\n",
        "model_o1=model_o[0][0]\n",
        "model_o2=model_o[0][1]\n",
        "\n",
        "matt_o1=0.75136507\n",
        "matt_o2=0.772928465\n",
        "model_diff_o1 = model_o1-matt_o1\n",
        "model_diff_o2 = model_o2-matt_o2\n",
        "print('Model out o1= {0:.9f}'.format(model_o1)+ ' Model out o2= {0:.9f}'.format(model_o2))\n",
        "print('Matt  out o1= {0:.9f}'.format(matt_o1)+ ' Matt  out o2= {0:.9f}'.format(matt_o2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic-ybFtJM1EF",
        "outputId": "4371466b-26c9-43bf-e8f4-1dd257ee46f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model out o1= 0.751747072 Model out o2= 0.773371816\n",
            "Matt  out o1= 0.751365070 Matt  out o2= 0.772928465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile Matt Model with loss=MeanSquarredError\n",
        "\n",
        "\n",
        "*   fit model on 1 input to see\n",
        "    gradients w1 to w4 on layer1 after 1 backpropagation\n",
        "*   fit model on a second input ( the same input) to see\n",
        "    gradients w5 to w8 on layer2 after 2 backpropagation\n"
      ],
      "metadata": {
        "id": "l8vxiZbMYtyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# matt inputs\n",
        "inputs = tf.constant([[0.05, 0.1]])\n",
        "batch_input=np.vstack([inputs]*2)\n",
        "\n",
        "W1 = np.array([[0.15,0.25],[0.2,0.3]]) # we initialize the weights according to Mattews example\n",
        "b1 = np.array([0.35,0.35])             # we initialize biases according to Mattews example\n",
        "setBias1=SetBias(0.35)\n",
        "#\n",
        "\n",
        "W2 = np.array([[0.4,0.5],[0.45,0.55]])\n",
        "b2 = np.array([0.6,0.6])\n",
        "setBias2=SetBias(0.6)"
      ],
      "metadata": {
        "id": "Rv5ixNJlDIVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "setBias1=SetBias(0.35)\n",
        "dense_layer1 = layers.Dense(units=2,\n",
        "                            use_bias=True,\n",
        "                            bias_constraint=setBias1,\n",
        "                            weights = [W1,b1],\n",
        "                            activation=activations.sigmoid,\n",
        "                            name='layer1'\n",
        "                            )\n",
        "setBias1=SetBias(0.60)\n",
        "dense_layer2 = layers.Dense(units=2,\n",
        "                            use_bias=True,\n",
        "                            bias_constraint=setBias2,\n",
        "                            weights = [W2,b2],\n",
        "                            activation=activations.sigmoid,\n",
        "                            name='layer2'\n",
        "                            )\n",
        "\n",
        "#creation of the Mattews model\n",
        "\n",
        "layer_inputs = Input(shape=(2,))\n",
        "out_layer1=dense_layer1(layer_inputs)\n",
        "out_layer2=dense_layer2(out_layer1)\n",
        "matt_model=Model(layer_inputs,out_layer2)\n",
        "matt_model.summary()\n",
        "\n",
        "#test model\n",
        "model_o=matt_model(inputs)\n",
        "model_o1=model_o[0][0]\n",
        "model_o2=model_o[0][1]\n",
        "\n",
        "matt_o1=0.75136507\n",
        "matt_o2=0.772928465\n",
        "model_diff_o1 = model_o1-matt_o1\n",
        "model_diff_o2 = model_o2-matt_o2\n",
        "print('Model out o1= {0:.9f}'.format(model_o1)+ ' Model out o2= {0:.9f}'.format(model_o2))\n",
        "print('Matt  out o1= {0:.9f}'.format(matt_o1)+ ' Matt  out o2= {0:.9f}'.format(matt_o2))\n",
        "\n",
        "# Compile model\n",
        "matt_model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=optimizers.legacy.SGD(learning_rate=0.5), metrics=['accuracy'])\n",
        "\n",
        "#training dataset\n",
        "x_tr=np.vstack([inputs]*1)\n",
        "y_true=np.array([0.01,0.99])\n",
        "y_tr=np.vstack([y_true]*1)\n",
        "\n",
        "#Let's train on only one backpropagation\n",
        "#matt_model.fit(x_tr, y_tr, epochs=1, batch_size=1, verbose=1, validation_split=0.0)\n",
        "#matt_model.summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA3zd9XbDiIA",
        "outputId": "106711c8-5bab-4f7a-a5ce-8ffa722c2da5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " layer1 (Dense)              (None, 2)                 6         \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 2)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12 (48.00 Byte)\n",
            "Trainable params: 12 (48.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model out o1= 0.751365066 Model out o2= 0.772928476\n",
            "Matt  out o1= 0.751365070 Matt  out o2= 0.772928465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#after 1 training (1 back propagation) Weights at step 1:\n",
        "matt_model.fit(x_tr, y_tr, epochs=1, batch_size=1, verbose=1, validation_split=0.0)\n",
        "matt_model.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whix8rKj9FtY",
        "outputId": "351b08bb-79d3-4905-d8bb-7b233387f80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 427ms/step - loss: 0.2984 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'layer1/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[0.14978072, 0.24975115],\n",
              "        [0.19956143, 0.2995023 ]], dtype=float32)>,\n",
              " <tf.Variable 'layer1/bias:0' shape=(2,) dtype=float32, numpy=array([0.35, 0.35], dtype=float32)>,\n",
              " <tf.Variable 'layer2/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[0.3589165 , 0.5113013 ],\n",
              "        [0.40866616, 0.56137013]], dtype=float32)>,\n",
              " <tf.Variable 'layer2/bias:0' shape=(2,) dtype=float32, numpy=array([0.6, 0.6], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run a second backward propagation"
      ],
      "metadata": {
        "id": "di_dXb9AuY-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#after 2 training of 1 epoch of batch=1 (2 back propagations) Weights at step 2:\n",
        "matt_model.fit(x_tr, y_tr, epochs=1, batch_size=1, verbose=1, validation_split=0.0)\n",
        "matt_model.trainable_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUVWFH07BNax",
        "outputId": "12d05adb-3f20-4da1-bb55-872b02ee1f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2910 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'layer1/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[0.14959273, 0.24953303],\n",
              "        [0.19918543, 0.29906607]], dtype=float32)>,\n",
              " <tf.Variable 'layer1/bias:0' shape=(2,) dtype=float32, numpy=array([0.35, 0.35], dtype=float32)>,\n",
              " <tf.Variable 'layer2/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[0.31735387, 0.52239734],\n",
              "        [0.36685044, 0.5725338 ]], dtype=float32)>,\n",
              " <tf.Variable 'layer2/bias:0' shape=(2,) dtype=float32, numpy=array([0.6, 0.6], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model on 1000 epoch\n",
        "  The output should be close to [0.01, 0.99]\n",
        "\n"
      ],
      "metadata": {
        "id": "3p9sPU4IurMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#training dataset\n",
        "x_tr=np.vstack([inputs]*10)\n",
        "y_true=np.array([0.01,0.99])\n",
        "y_tr=np.vstack([y_true]*10)\n",
        "\n",
        "#Let's train on only one backpropagation\n",
        "history=matt_model.fit(x_tr, y_tr, epochs=1000, batch_size=1, verbose=1, validation_split=0.0)\n",
        "#matt_model.summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eShOW6ON88_5",
        "outputId": "8ae81bcb-5892-478d-e72a-8ccce0ae4e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 1.0000\n",
            "Epoch 2/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 1.0000\n",
            "Epoch 3/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 1.0000\n",
            "Epoch 4/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 1.0000\n",
            "Epoch 5/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 1.0000\n",
            "Epoch 6/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 1.0000\n",
            "Epoch 7/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 1.0000\n",
            "Epoch 8/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 1.0000\n",
            "Epoch 9/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 10/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 11/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 12/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 1.0000\n",
            "Epoch 13/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 14/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 1.0000\n",
            "Epoch 15/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 16/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 17/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 18/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "Epoch 19/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 20/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 21/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 22/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 23/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 24/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 25/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 26/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 27/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 28/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 29/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 30/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 31/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 32/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 33/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 34/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 35/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 36/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 37/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 38/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 39/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 40/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 41/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 42/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 43/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 44/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 45/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 46/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 47/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 49/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 50/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 51/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 52/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 53/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 54/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 55/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 56/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 57/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 58/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 59/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 60/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 61/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 62/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 63/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 64/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 65/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 66/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 67/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 68/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 69/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 70/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 71/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 72/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 73/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 74/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 76/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 77/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 78/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 79/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 80/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 81/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 82/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 85/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 86/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 88/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 89/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 90/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 91/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 92/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 93/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 94/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 95/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 96/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 97/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 98/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 99/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 100/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 101/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 102/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 103/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 104/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 105/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 106/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 107/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 109/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 110/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.8937e-04 - accuracy: 1.0000\n",
            "Epoch 111/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.7779e-04 - accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.6645e-04 - accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.5533e-04 - accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.4443e-04 - accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.3374e-04 - accuracy: 1.0000\n",
            "Epoch 116/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.2325e-04 - accuracy: 1.0000\n",
            "Epoch 117/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.1297e-04 - accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.0288e-04 - accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.9297e-04 - accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.8325e-04 - accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.7371e-04 - accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.6435e-04 - accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.5515e-04 - accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.4612e-04 - accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.3726e-04 - accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.2854e-04 - accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.1999e-04 - accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.1158e-04 - accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.0331e-04 - accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.9519e-04 - accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.8721e-04 - accuracy: 1.0000\n",
            "Epoch 132/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.7936e-04 - accuracy: 1.0000\n",
            "Epoch 133/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.7164e-04 - accuracy: 1.0000\n",
            "Epoch 134/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.6406e-04 - accuracy: 1.0000\n",
            "Epoch 135/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.5659e-04 - accuracy: 1.0000\n",
            "Epoch 136/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.4925e-04 - accuracy: 1.0000\n",
            "Epoch 137/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.4203e-04 - accuracy: 1.0000\n",
            "Epoch 138/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.3493e-04 - accuracy: 1.0000\n",
            "Epoch 139/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2794e-04 - accuracy: 1.0000\n",
            "Epoch 140/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2107e-04 - accuracy: 1.0000\n",
            "Epoch 141/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.1430e-04 - accuracy: 1.0000\n",
            "Epoch 142/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.0764e-04 - accuracy: 1.0000\n",
            "Epoch 143/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.0108e-04 - accuracy: 1.0000\n",
            "Epoch 144/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.9462e-04 - accuracy: 1.0000\n",
            "Epoch 145/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.8827e-04 - accuracy: 1.0000\n",
            "Epoch 146/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.8201e-04 - accuracy: 1.0000\n",
            "Epoch 147/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.7585e-04 - accuracy: 1.0000\n",
            "Epoch 148/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.6978e-04 - accuracy: 1.0000\n",
            "Epoch 149/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.6380e-04 - accuracy: 1.0000\n",
            "Epoch 150/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.5791e-04 - accuracy: 1.0000\n",
            "Epoch 151/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.5211e-04 - accuracy: 1.0000\n",
            "Epoch 152/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.4639e-04 - accuracy: 1.0000\n",
            "Epoch 153/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.4076e-04 - accuracy: 1.0000\n",
            "Epoch 154/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.3521e-04 - accuracy: 1.0000\n",
            "Epoch 155/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.2974e-04 - accuracy: 1.0000\n",
            "Epoch 156/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.2434e-04 - accuracy: 1.0000\n",
            "Epoch 157/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.1903e-04 - accuracy: 1.0000\n",
            "Epoch 158/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.1379e-04 - accuracy: 1.0000\n",
            "Epoch 159/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.0862e-04 - accuracy: 1.0000\n",
            "Epoch 160/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 6.0353e-04 - accuracy: 1.0000\n",
            "Epoch 161/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.9851e-04 - accuracy: 1.0000\n",
            "Epoch 162/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.9356e-04 - accuracy: 1.0000\n",
            "Epoch 163/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.8867e-04 - accuracy: 1.0000\n",
            "Epoch 164/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.8385e-04 - accuracy: 1.0000\n",
            "Epoch 165/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.7910e-04 - accuracy: 1.0000\n",
            "Epoch 166/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.7441e-04 - accuracy: 1.0000\n",
            "Epoch 167/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.6979e-04 - accuracy: 1.0000\n",
            "Epoch 168/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.6522e-04 - accuracy: 1.0000\n",
            "Epoch 169/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.6072e-04 - accuracy: 1.0000\n",
            "Epoch 170/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.5628e-04 - accuracy: 1.0000\n",
            "Epoch 171/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.5189e-04 - accuracy: 1.0000\n",
            "Epoch 172/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.4757e-04 - accuracy: 1.0000\n",
            "Epoch 173/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.4330e-04 - accuracy: 1.0000\n",
            "Epoch 174/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3908e-04 - accuracy: 1.0000\n",
            "Epoch 175/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3492e-04 - accuracy: 1.0000\n",
            "Epoch 176/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3081e-04 - accuracy: 1.0000\n",
            "Epoch 177/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2675e-04 - accuracy: 1.0000\n",
            "Epoch 178/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2275e-04 - accuracy: 1.0000\n",
            "Epoch 179/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1879e-04 - accuracy: 1.0000\n",
            "Epoch 180/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1489e-04 - accuracy: 1.0000\n",
            "Epoch 181/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1103e-04 - accuracy: 1.0000\n",
            "Epoch 182/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.0722e-04 - accuracy: 1.0000\n",
            "Epoch 183/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.0346e-04 - accuracy: 1.0000\n",
            "Epoch 184/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.9974e-04 - accuracy: 1.0000\n",
            "Epoch 185/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.9607e-04 - accuracy: 1.0000\n",
            "Epoch 186/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.9244e-04 - accuracy: 1.0000\n",
            "Epoch 187/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.8886e-04 - accuracy: 1.0000\n",
            "Epoch 188/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.8532e-04 - accuracy: 1.0000\n",
            "Epoch 189/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.8182e-04 - accuracy: 1.0000\n",
            "Epoch 190/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.7837e-04 - accuracy: 1.0000\n",
            "Epoch 191/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.7495e-04 - accuracy: 1.0000\n",
            "Epoch 192/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.7158e-04 - accuracy: 1.0000\n",
            "Epoch 193/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.6824e-04 - accuracy: 1.0000\n",
            "Epoch 194/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.6494e-04 - accuracy: 1.0000\n",
            "Epoch 195/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.6168e-04 - accuracy: 1.0000\n",
            "Epoch 196/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.5846e-04 - accuracy: 1.0000\n",
            "Epoch 197/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.5528e-04 - accuracy: 1.0000\n",
            "Epoch 198/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.5213e-04 - accuracy: 1.0000\n",
            "Epoch 199/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.4902e-04 - accuracy: 1.0000\n",
            "Epoch 200/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.4594e-04 - accuracy: 1.0000\n",
            "Epoch 201/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.4289e-04 - accuracy: 1.0000\n",
            "Epoch 202/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.3989e-04 - accuracy: 1.0000\n",
            "Epoch 203/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.3691e-04 - accuracy: 1.0000\n",
            "Epoch 204/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.3397e-04 - accuracy: 1.0000\n",
            "Epoch 205/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.3106e-04 - accuracy: 1.0000\n",
            "Epoch 206/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.2818e-04 - accuracy: 1.0000\n",
            "Epoch 207/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.2533e-04 - accuracy: 1.0000\n",
            "Epoch 208/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.2252e-04 - accuracy: 1.0000\n",
            "Epoch 209/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 4.1973e-04 - accuracy: 1.0000\n",
            "Epoch 210/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.1697e-04 - accuracy: 1.0000\n",
            "Epoch 211/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.1425e-04 - accuracy: 1.0000\n",
            "Epoch 212/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.1155e-04 - accuracy: 1.0000\n",
            "Epoch 213/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.0888e-04 - accuracy: 1.0000\n",
            "Epoch 214/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.0624e-04 - accuracy: 1.0000\n",
            "Epoch 215/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.0363e-04 - accuracy: 1.0000\n",
            "Epoch 216/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.0105e-04 - accuracy: 1.0000\n",
            "Epoch 217/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9849e-04 - accuracy: 1.0000\n",
            "Epoch 218/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9596e-04 - accuracy: 1.0000\n",
            "Epoch 219/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9345e-04 - accuracy: 1.0000\n",
            "Epoch 220/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9097e-04 - accuracy: 1.0000\n",
            "Epoch 221/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8852e-04 - accuracy: 1.0000\n",
            "Epoch 222/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8609e-04 - accuracy: 1.0000\n",
            "Epoch 223/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.8368e-04 - accuracy: 1.0000\n",
            "Epoch 224/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.8130e-04 - accuracy: 1.0000\n",
            "Epoch 225/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.7895e-04 - accuracy: 1.0000\n",
            "Epoch 226/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.7661e-04 - accuracy: 1.0000\n",
            "Epoch 227/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.7430e-04 - accuracy: 1.0000\n",
            "Epoch 228/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.7202e-04 - accuracy: 1.0000\n",
            "Epoch 229/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.6975e-04 - accuracy: 1.0000\n",
            "Epoch 230/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.6751e-04 - accuracy: 1.0000\n",
            "Epoch 231/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.6530e-04 - accuracy: 1.0000\n",
            "Epoch 232/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.6310e-04 - accuracy: 1.0000\n",
            "Epoch 233/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.6092e-04 - accuracy: 1.0000\n",
            "Epoch 234/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.5877e-04 - accuracy: 1.0000\n",
            "Epoch 235/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.5663e-04 - accuracy: 1.0000\n",
            "Epoch 236/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5452e-04 - accuracy: 1.0000\n",
            "Epoch 237/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5242e-04 - accuracy: 1.0000\n",
            "Epoch 238/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.5035e-04 - accuracy: 1.0000\n",
            "Epoch 239/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4830e-04 - accuracy: 1.0000\n",
            "Epoch 240/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4626e-04 - accuracy: 1.0000\n",
            "Epoch 241/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.4425e-04 - accuracy: 1.0000\n",
            "Epoch 242/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4225e-04 - accuracy: 1.0000\n",
            "Epoch 243/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.4027e-04 - accuracy: 1.0000\n",
            "Epoch 244/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 3.3831e-04 - accuracy: 1.0000\n",
            "Epoch 245/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3637e-04 - accuracy: 1.0000\n",
            "Epoch 246/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3445e-04 - accuracy: 1.0000\n",
            "Epoch 247/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.3255e-04 - accuracy: 1.0000\n",
            "Epoch 248/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3066e-04 - accuracy: 1.0000\n",
            "Epoch 249/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.2879e-04 - accuracy: 1.0000\n",
            "Epoch 250/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2693e-04 - accuracy: 1.0000\n",
            "Epoch 251/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2510e-04 - accuracy: 1.0000\n",
            "Epoch 252/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2328e-04 - accuracy: 1.0000\n",
            "Epoch 253/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.2147e-04 - accuracy: 1.0000\n",
            "Epoch 254/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1969e-04 - accuracy: 1.0000\n",
            "Epoch 255/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1791e-04 - accuracy: 1.0000\n",
            "Epoch 256/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.1616e-04 - accuracy: 1.0000\n",
            "Epoch 257/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1442e-04 - accuracy: 1.0000\n",
            "Epoch 258/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.1269e-04 - accuracy: 1.0000\n",
            "Epoch 259/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.1098e-04 - accuracy: 1.0000\n",
            "Epoch 260/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.0929e-04 - accuracy: 1.0000\n",
            "Epoch 261/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0761e-04 - accuracy: 1.0000\n",
            "Epoch 262/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.0594e-04 - accuracy: 1.0000\n",
            "Epoch 263/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0429e-04 - accuracy: 1.0000\n",
            "Epoch 264/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 3.0266e-04 - accuracy: 1.0000\n",
            "Epoch 265/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0103e-04 - accuracy: 1.0000\n",
            "Epoch 266/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9942e-04 - accuracy: 1.0000\n",
            "Epoch 267/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9783e-04 - accuracy: 1.0000\n",
            "Epoch 268/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9625e-04 - accuracy: 1.0000\n",
            "Epoch 269/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.9468e-04 - accuracy: 1.0000\n",
            "Epoch 270/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.9313e-04 - accuracy: 1.0000\n",
            "Epoch 271/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.9158e-04 - accuracy: 1.0000\n",
            "Epoch 272/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.9006e-04 - accuracy: 1.0000\n",
            "Epoch 273/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8854e-04 - accuracy: 1.0000\n",
            "Epoch 274/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.8704e-04 - accuracy: 1.0000\n",
            "Epoch 275/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.8555e-04 - accuracy: 1.0000\n",
            "Epoch 276/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.8407e-04 - accuracy: 1.0000\n",
            "Epoch 277/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.8260e-04 - accuracy: 1.0000\n",
            "Epoch 278/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.8115e-04 - accuracy: 1.0000\n",
            "Epoch 279/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.7971e-04 - accuracy: 1.0000\n",
            "Epoch 280/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.7828e-04 - accuracy: 1.0000\n",
            "Epoch 281/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7686e-04 - accuracy: 1.0000\n",
            "Epoch 282/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7545e-04 - accuracy: 1.0000\n",
            "Epoch 283/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.7405e-04 - accuracy: 1.0000\n",
            "Epoch 284/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.7267e-04 - accuracy: 1.0000\n",
            "Epoch 285/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.7130e-04 - accuracy: 1.0000\n",
            "Epoch 286/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.6993e-04 - accuracy: 1.0000\n",
            "Epoch 287/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6858e-04 - accuracy: 1.0000\n",
            "Epoch 288/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.6724e-04 - accuracy: 1.0000\n",
            "Epoch 289/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6591e-04 - accuracy: 1.0000\n",
            "Epoch 290/1000\n",
            "10/10 [==============================] - 0s 13ms/step - loss: 2.6459e-04 - accuracy: 1.0000\n",
            "Epoch 291/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.6328e-04 - accuracy: 1.0000\n",
            "Epoch 292/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.6198e-04 - accuracy: 1.0000\n",
            "Epoch 293/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.6070e-04 - accuracy: 1.0000\n",
            "Epoch 294/1000\n",
            "10/10 [==============================] - 0s 16ms/step - loss: 2.5942e-04 - accuracy: 1.0000\n",
            "Epoch 295/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5815e-04 - accuracy: 1.0000\n",
            "Epoch 296/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.5689e-04 - accuracy: 1.0000\n",
            "Epoch 297/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5564e-04 - accuracy: 1.0000\n",
            "Epoch 298/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.5440e-04 - accuracy: 1.0000\n",
            "Epoch 299/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.5317e-04 - accuracy: 1.0000\n",
            "Epoch 300/1000\n",
            "10/10 [==============================] - 0s 12ms/step - loss: 2.5195e-04 - accuracy: 1.0000\n",
            "Epoch 301/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5074e-04 - accuracy: 1.0000\n",
            "Epoch 302/1000\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 2.4954e-04 - accuracy: 1.0000\n",
            "Epoch 303/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.4834e-04 - accuracy: 1.0000\n",
            "Epoch 304/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4716e-04 - accuracy: 1.0000\n",
            "Epoch 305/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.4598e-04 - accuracy: 1.0000\n",
            "Epoch 306/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4482e-04 - accuracy: 1.0000\n",
            "Epoch 307/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.4366e-04 - accuracy: 1.0000\n",
            "Epoch 308/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.4251e-04 - accuracy: 1.0000\n",
            "Epoch 309/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4137e-04 - accuracy: 1.0000\n",
            "Epoch 310/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.4024e-04 - accuracy: 1.0000\n",
            "Epoch 311/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.3911e-04 - accuracy: 1.0000\n",
            "Epoch 312/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.3800e-04 - accuracy: 1.0000\n",
            "Epoch 313/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.3689e-04 - accuracy: 1.0000\n",
            "Epoch 314/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.3579e-04 - accuracy: 1.0000\n",
            "Epoch 315/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3470e-04 - accuracy: 1.0000\n",
            "Epoch 316/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3362e-04 - accuracy: 1.0000\n",
            "Epoch 317/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.3254e-04 - accuracy: 1.0000\n",
            "Epoch 318/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.3148e-04 - accuracy: 1.0000\n",
            "Epoch 319/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.3042e-04 - accuracy: 1.0000\n",
            "Epoch 320/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.2937e-04 - accuracy: 1.0000\n",
            "Epoch 321/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2832e-04 - accuracy: 1.0000\n",
            "Epoch 322/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2728e-04 - accuracy: 1.0000\n",
            "Epoch 323/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.2625e-04 - accuracy: 1.0000\n",
            "Epoch 324/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.2523e-04 - accuracy: 1.0000\n",
            "Epoch 325/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2422e-04 - accuracy: 1.0000\n",
            "Epoch 326/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.2321e-04 - accuracy: 1.0000\n",
            "Epoch 327/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.2221e-04 - accuracy: 1.0000\n",
            "Epoch 328/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.2121e-04 - accuracy: 1.0000\n",
            "Epoch 329/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.2023e-04 - accuracy: 1.0000\n",
            "Epoch 330/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1925e-04 - accuracy: 1.0000\n",
            "Epoch 331/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1828e-04 - accuracy: 1.0000\n",
            "Epoch 332/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.1731e-04 - accuracy: 1.0000\n",
            "Epoch 333/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 2.1635e-04 - accuracy: 1.0000\n",
            "Epoch 334/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.1540e-04 - accuracy: 1.0000\n",
            "Epoch 335/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.1445e-04 - accuracy: 1.0000\n",
            "Epoch 336/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1351e-04 - accuracy: 1.0000\n",
            "Epoch 337/1000\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.1258e-04 - accuracy: 1.0000\n",
            "Epoch 338/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.1165e-04 - accuracy: 1.0000\n",
            "Epoch 339/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1073e-04 - accuracy: 1.0000\n",
            "Epoch 340/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.0982e-04 - accuracy: 1.0000\n",
            "Epoch 341/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.0891e-04 - accuracy: 1.0000\n",
            "Epoch 342/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.0800e-04 - accuracy: 1.0000\n",
            "Epoch 343/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.0711e-04 - accuracy: 1.0000\n",
            "Epoch 344/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0622e-04 - accuracy: 1.0000\n",
            "Epoch 345/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0534e-04 - accuracy: 1.0000\n",
            "Epoch 346/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0446e-04 - accuracy: 1.0000\n",
            "Epoch 347/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0358e-04 - accuracy: 1.0000\n",
            "Epoch 348/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0272e-04 - accuracy: 1.0000\n",
            "Epoch 349/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 2.0186e-04 - accuracy: 1.0000\n",
            "Epoch 350/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0100e-04 - accuracy: 1.0000\n",
            "Epoch 351/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 2.0015e-04 - accuracy: 1.0000\n",
            "Epoch 352/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9931e-04 - accuracy: 1.0000\n",
            "Epoch 353/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9847e-04 - accuracy: 1.0000\n",
            "Epoch 354/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9764e-04 - accuracy: 1.0000\n",
            "Epoch 355/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9681e-04 - accuracy: 1.0000\n",
            "Epoch 356/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9599e-04 - accuracy: 1.0000\n",
            "Epoch 357/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9517e-04 - accuracy: 1.0000\n",
            "Epoch 358/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9436e-04 - accuracy: 1.0000\n",
            "Epoch 359/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9356e-04 - accuracy: 1.0000\n",
            "Epoch 360/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.9275e-04 - accuracy: 1.0000\n",
            "Epoch 361/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9196e-04 - accuracy: 1.0000\n",
            "Epoch 362/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9117e-04 - accuracy: 1.0000\n",
            "Epoch 363/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.9038e-04 - accuracy: 1.0000\n",
            "Epoch 364/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8960e-04 - accuracy: 1.0000\n",
            "Epoch 365/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8883e-04 - accuracy: 1.0000\n",
            "Epoch 366/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8806e-04 - accuracy: 1.0000\n",
            "Epoch 367/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8729e-04 - accuracy: 1.0000\n",
            "Epoch 368/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8653e-04 - accuracy: 1.0000\n",
            "Epoch 369/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8577e-04 - accuracy: 1.0000\n",
            "Epoch 370/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8502e-04 - accuracy: 1.0000\n",
            "Epoch 371/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8427e-04 - accuracy: 1.0000\n",
            "Epoch 372/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.8353e-04 - accuracy: 1.0000\n",
            "Epoch 373/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8280e-04 - accuracy: 1.0000\n",
            "Epoch 374/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8206e-04 - accuracy: 1.0000\n",
            "Epoch 375/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8133e-04 - accuracy: 1.0000\n",
            "Epoch 376/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.8061e-04 - accuracy: 1.0000\n",
            "Epoch 377/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7989e-04 - accuracy: 1.0000\n",
            "Epoch 378/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7918e-04 - accuracy: 1.0000\n",
            "Epoch 379/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7847e-04 - accuracy: 1.0000\n",
            "Epoch 380/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7776e-04 - accuracy: 1.0000\n",
            "Epoch 381/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7706e-04 - accuracy: 1.0000\n",
            "Epoch 382/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7636e-04 - accuracy: 1.0000\n",
            "Epoch 383/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7567e-04 - accuracy: 1.0000\n",
            "Epoch 384/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.7498e-04 - accuracy: 1.0000\n",
            "Epoch 385/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7429e-04 - accuracy: 1.0000\n",
            "Epoch 386/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7361e-04 - accuracy: 1.0000\n",
            "Epoch 387/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7294e-04 - accuracy: 1.0000\n",
            "Epoch 388/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7226e-04 - accuracy: 1.0000\n",
            "Epoch 389/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7159e-04 - accuracy: 1.0000\n",
            "Epoch 390/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7093e-04 - accuracy: 1.0000\n",
            "Epoch 391/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.7027e-04 - accuracy: 1.0000\n",
            "Epoch 392/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6961e-04 - accuracy: 1.0000\n",
            "Epoch 393/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6896e-04 - accuracy: 1.0000\n",
            "Epoch 394/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6831e-04 - accuracy: 1.0000\n",
            "Epoch 395/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6767e-04 - accuracy: 1.0000\n",
            "Epoch 396/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6702e-04 - accuracy: 1.0000\n",
            "Epoch 397/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6639e-04 - accuracy: 1.0000\n",
            "Epoch 398/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6575e-04 - accuracy: 1.0000\n",
            "Epoch 399/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6512e-04 - accuracy: 1.0000\n",
            "Epoch 400/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6450e-04 - accuracy: 1.0000\n",
            "Epoch 401/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6387e-04 - accuracy: 1.0000\n",
            "Epoch 402/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6325e-04 - accuracy: 1.0000\n",
            "Epoch 403/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6264e-04 - accuracy: 1.0000\n",
            "Epoch 404/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6203e-04 - accuracy: 1.0000\n",
            "Epoch 405/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.6142e-04 - accuracy: 1.0000\n",
            "Epoch 406/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6081e-04 - accuracy: 1.0000\n",
            "Epoch 407/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.6021e-04 - accuracy: 1.0000\n",
            "Epoch 408/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5961e-04 - accuracy: 1.0000\n",
            "Epoch 409/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5902e-04 - accuracy: 1.0000\n",
            "Epoch 410/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5843e-04 - accuracy: 1.0000\n",
            "Epoch 411/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5784e-04 - accuracy: 1.0000\n",
            "Epoch 412/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5726e-04 - accuracy: 1.0000\n",
            "Epoch 413/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5667e-04 - accuracy: 1.0000\n",
            "Epoch 414/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5610e-04 - accuracy: 1.0000\n",
            "Epoch 415/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5552e-04 - accuracy: 1.0000\n",
            "Epoch 416/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5495e-04 - accuracy: 1.0000\n",
            "Epoch 417/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5438e-04 - accuracy: 1.0000\n",
            "Epoch 418/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.5382e-04 - accuracy: 1.0000\n",
            "Epoch 419/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5325e-04 - accuracy: 1.0000\n",
            "Epoch 420/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5270e-04 - accuracy: 1.0000\n",
            "Epoch 421/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5214e-04 - accuracy: 1.0000\n",
            "Epoch 422/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5159e-04 - accuracy: 1.0000\n",
            "Epoch 423/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5104e-04 - accuracy: 1.0000\n",
            "Epoch 424/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.5049e-04 - accuracy: 1.0000\n",
            "Epoch 425/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4995e-04 - accuracy: 1.0000\n",
            "Epoch 426/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4941e-04 - accuracy: 1.0000\n",
            "Epoch 427/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4887e-04 - accuracy: 1.0000\n",
            "Epoch 428/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4834e-04 - accuracy: 1.0000\n",
            "Epoch 429/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4780e-04 - accuracy: 1.0000\n",
            "Epoch 430/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4728e-04 - accuracy: 1.0000\n",
            "Epoch 431/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4675e-04 - accuracy: 1.0000\n",
            "Epoch 432/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4623e-04 - accuracy: 1.0000\n",
            "Epoch 433/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4571e-04 - accuracy: 1.0000\n",
            "Epoch 434/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4519e-04 - accuracy: 1.0000\n",
            "Epoch 435/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4467e-04 - accuracy: 1.0000\n",
            "Epoch 436/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4416e-04 - accuracy: 1.0000\n",
            "Epoch 437/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4365e-04 - accuracy: 1.0000\n",
            "Epoch 438/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4315e-04 - accuracy: 1.0000\n",
            "Epoch 439/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4264e-04 - accuracy: 1.0000\n",
            "Epoch 440/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4214e-04 - accuracy: 1.0000\n",
            "Epoch 441/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4165e-04 - accuracy: 1.0000\n",
            "Epoch 442/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4115e-04 - accuracy: 1.0000\n",
            "Epoch 443/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.4066e-04 - accuracy: 1.0000\n",
            "Epoch 444/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.4017e-04 - accuracy: 1.0000\n",
            "Epoch 445/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3968e-04 - accuracy: 1.0000\n",
            "Epoch 446/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1.3919e-04 - accuracy: 1.0000\n",
            "Epoch 447/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3871e-04 - accuracy: 1.0000\n",
            "Epoch 448/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3823e-04 - accuracy: 1.0000\n",
            "Epoch 449/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3775e-04 - accuracy: 1.0000\n",
            "Epoch 450/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3728e-04 - accuracy: 1.0000\n",
            "Epoch 451/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3681e-04 - accuracy: 1.0000\n",
            "Epoch 452/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3634e-04 - accuracy: 1.0000\n",
            "Epoch 453/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3587e-04 - accuracy: 1.0000\n",
            "Epoch 454/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3540e-04 - accuracy: 1.0000\n",
            "Epoch 455/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3494e-04 - accuracy: 1.0000\n",
            "Epoch 456/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3448e-04 - accuracy: 1.0000\n",
            "Epoch 457/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3402e-04 - accuracy: 1.0000\n",
            "Epoch 458/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3357e-04 - accuracy: 1.0000\n",
            "Epoch 459/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3311e-04 - accuracy: 1.0000\n",
            "Epoch 460/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3266e-04 - accuracy: 1.0000\n",
            "Epoch 461/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3221e-04 - accuracy: 1.0000\n",
            "Epoch 462/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3177e-04 - accuracy: 1.0000\n",
            "Epoch 463/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3132e-04 - accuracy: 1.0000\n",
            "Epoch 464/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3088e-04 - accuracy: 1.0000\n",
            "Epoch 465/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.3044e-04 - accuracy: 1.0000\n",
            "Epoch 466/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.3000e-04 - accuracy: 1.0000\n",
            "Epoch 467/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2957e-04 - accuracy: 1.0000\n",
            "Epoch 468/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2914e-04 - accuracy: 1.0000\n",
            "Epoch 469/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2871e-04 - accuracy: 1.0000\n",
            "Epoch 470/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2828e-04 - accuracy: 1.0000\n",
            "Epoch 471/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2785e-04 - accuracy: 1.0000\n",
            "Epoch 472/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2743e-04 - accuracy: 1.0000\n",
            "Epoch 473/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2700e-04 - accuracy: 1.0000\n",
            "Epoch 474/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2658e-04 - accuracy: 1.0000\n",
            "Epoch 475/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2617e-04 - accuracy: 1.0000\n",
            "Epoch 476/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2575e-04 - accuracy: 1.0000\n",
            "Epoch 477/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2534e-04 - accuracy: 1.0000\n",
            "Epoch 478/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2492e-04 - accuracy: 1.0000\n",
            "Epoch 479/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2451e-04 - accuracy: 1.0000\n",
            "Epoch 480/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2411e-04 - accuracy: 1.0000\n",
            "Epoch 481/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2370e-04 - accuracy: 1.0000\n",
            "Epoch 482/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2330e-04 - accuracy: 1.0000\n",
            "Epoch 483/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2289e-04 - accuracy: 1.0000\n",
            "Epoch 484/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2250e-04 - accuracy: 1.0000\n",
            "Epoch 485/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2210e-04 - accuracy: 1.0000\n",
            "Epoch 486/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2170e-04 - accuracy: 1.0000\n",
            "Epoch 487/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.2131e-04 - accuracy: 1.0000\n",
            "Epoch 488/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2092e-04 - accuracy: 1.0000\n",
            "Epoch 489/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2052e-04 - accuracy: 1.0000\n",
            "Epoch 490/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.2014e-04 - accuracy: 1.0000\n",
            "Epoch 491/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1975e-04 - accuracy: 1.0000\n",
            "Epoch 492/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1937e-04 - accuracy: 1.0000\n",
            "Epoch 493/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1898e-04 - accuracy: 1.0000\n",
            "Epoch 494/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1860e-04 - accuracy: 1.0000\n",
            "Epoch 495/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1822e-04 - accuracy: 1.0000\n",
            "Epoch 496/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1785e-04 - accuracy: 1.0000\n",
            "Epoch 497/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1747e-04 - accuracy: 1.0000\n",
            "Epoch 498/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1710e-04 - accuracy: 1.0000\n",
            "Epoch 499/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1672e-04 - accuracy: 1.0000\n",
            "Epoch 500/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1635e-04 - accuracy: 1.0000\n",
            "Epoch 501/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1599e-04 - accuracy: 1.0000\n",
            "Epoch 502/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1562e-04 - accuracy: 1.0000\n",
            "Epoch 503/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1526e-04 - accuracy: 1.0000\n",
            "Epoch 504/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1489e-04 - accuracy: 1.0000\n",
            "Epoch 505/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1453e-04 - accuracy: 1.0000\n",
            "Epoch 506/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1417e-04 - accuracy: 1.0000\n",
            "Epoch 507/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1381e-04 - accuracy: 1.0000\n",
            "Epoch 508/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1346e-04 - accuracy: 1.0000\n",
            "Epoch 509/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1310e-04 - accuracy: 1.0000\n",
            "Epoch 510/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1275e-04 - accuracy: 1.0000\n",
            "Epoch 511/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1240e-04 - accuracy: 1.0000\n",
            "Epoch 512/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1205e-04 - accuracy: 1.0000\n",
            "Epoch 513/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1170e-04 - accuracy: 1.0000\n",
            "Epoch 514/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1135e-04 - accuracy: 1.0000\n",
            "Epoch 515/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.1101e-04 - accuracy: 1.0000\n",
            "Epoch 516/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1066e-04 - accuracy: 1.0000\n",
            "Epoch 517/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.1032e-04 - accuracy: 1.0000\n",
            "Epoch 518/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0998e-04 - accuracy: 1.0000\n",
            "Epoch 519/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0964e-04 - accuracy: 1.0000\n",
            "Epoch 520/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0931e-04 - accuracy: 1.0000\n",
            "Epoch 521/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0897e-04 - accuracy: 1.0000\n",
            "Epoch 522/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0864e-04 - accuracy: 1.0000\n",
            "Epoch 523/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0831e-04 - accuracy: 1.0000\n",
            "Epoch 524/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0797e-04 - accuracy: 1.0000\n",
            "Epoch 525/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0764e-04 - accuracy: 1.0000\n",
            "Epoch 526/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0732e-04 - accuracy: 1.0000\n",
            "Epoch 527/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0699e-04 - accuracy: 1.0000\n",
            "Epoch 528/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0667e-04 - accuracy: 1.0000\n",
            "Epoch 529/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0634e-04 - accuracy: 1.0000\n",
            "Epoch 530/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0602e-04 - accuracy: 1.0000\n",
            "Epoch 531/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0570e-04 - accuracy: 1.0000\n",
            "Epoch 532/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0538e-04 - accuracy: 1.0000\n",
            "Epoch 533/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0506e-04 - accuracy: 1.0000\n",
            "Epoch 534/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0475e-04 - accuracy: 1.0000\n",
            "Epoch 535/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0443e-04 - accuracy: 1.0000\n",
            "Epoch 536/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0412e-04 - accuracy: 1.0000\n",
            "Epoch 537/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0381e-04 - accuracy: 1.0000\n",
            "Epoch 538/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0349e-04 - accuracy: 1.0000\n",
            "Epoch 539/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0319e-04 - accuracy: 1.0000\n",
            "Epoch 540/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0288e-04 - accuracy: 1.0000\n",
            "Epoch 541/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0257e-04 - accuracy: 1.0000\n",
            "Epoch 542/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0227e-04 - accuracy: 1.0000\n",
            "Epoch 543/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0196e-04 - accuracy: 1.0000\n",
            "Epoch 544/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0166e-04 - accuracy: 1.0000\n",
            "Epoch 545/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0136e-04 - accuracy: 1.0000\n",
            "Epoch 546/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0106e-04 - accuracy: 1.0000\n",
            "Epoch 547/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0076e-04 - accuracy: 1.0000\n",
            "Epoch 548/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 1.0046e-04 - accuracy: 1.0000\n",
            "Epoch 549/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 1.0017e-04 - accuracy: 1.0000\n",
            "Epoch 550/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.9871e-05 - accuracy: 1.0000\n",
            "Epoch 551/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.9578e-05 - accuracy: 1.0000\n",
            "Epoch 552/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.9286e-05 - accuracy: 1.0000\n",
            "Epoch 553/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.8995e-05 - accuracy: 1.0000\n",
            "Epoch 554/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.8705e-05 - accuracy: 1.0000\n",
            "Epoch 555/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.8417e-05 - accuracy: 1.0000\n",
            "Epoch 556/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.8130e-05 - accuracy: 1.0000\n",
            "Epoch 557/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.7843e-05 - accuracy: 1.0000\n",
            "Epoch 558/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.7559e-05 - accuracy: 1.0000\n",
            "Epoch 559/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.7275e-05 - accuracy: 1.0000\n",
            "Epoch 560/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.6993e-05 - accuracy: 1.0000\n",
            "Epoch 561/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.6712e-05 - accuracy: 1.0000\n",
            "Epoch 562/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.6432e-05 - accuracy: 1.0000\n",
            "Epoch 563/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.6154e-05 - accuracy: 1.0000\n",
            "Epoch 564/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.5876e-05 - accuracy: 1.0000\n",
            "Epoch 565/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.5600e-05 - accuracy: 1.0000\n",
            "Epoch 566/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.5325e-05 - accuracy: 1.0000\n",
            "Epoch 567/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.5051e-05 - accuracy: 1.0000\n",
            "Epoch 568/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.4778e-05 - accuracy: 1.0000\n",
            "Epoch 569/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.4506e-05 - accuracy: 1.0000\n",
            "Epoch 570/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.4236e-05 - accuracy: 1.0000\n",
            "Epoch 571/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.3967e-05 - accuracy: 1.0000\n",
            "Epoch 572/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.3698e-05 - accuracy: 1.0000\n",
            "Epoch 573/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.3431e-05 - accuracy: 1.0000\n",
            "Epoch 574/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.3165e-05 - accuracy: 1.0000\n",
            "Epoch 575/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.2901e-05 - accuracy: 1.0000\n",
            "Epoch 576/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.2637e-05 - accuracy: 1.0000\n",
            "Epoch 577/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.2374e-05 - accuracy: 1.0000\n",
            "Epoch 578/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.2113e-05 - accuracy: 1.0000\n",
            "Epoch 579/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 9.1852e-05 - accuracy: 1.0000\n",
            "Epoch 580/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 9.1593e-05 - accuracy: 1.0000\n",
            "Epoch 581/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.1334e-05 - accuracy: 1.0000\n",
            "Epoch 582/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.1077e-05 - accuracy: 1.0000\n",
            "Epoch 583/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.0821e-05 - accuracy: 1.0000\n",
            "Epoch 584/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.0566e-05 - accuracy: 1.0000\n",
            "Epoch 585/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.0312e-05 - accuracy: 1.0000\n",
            "Epoch 586/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 9.0059e-05 - accuracy: 1.0000\n",
            "Epoch 587/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.9807e-05 - accuracy: 1.0000\n",
            "Epoch 588/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.9556e-05 - accuracy: 1.0000\n",
            "Epoch 589/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.9306e-05 - accuracy: 1.0000\n",
            "Epoch 590/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.9057e-05 - accuracy: 1.0000\n",
            "Epoch 591/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.8809e-05 - accuracy: 1.0000\n",
            "Epoch 592/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.8562e-05 - accuracy: 1.0000\n",
            "Epoch 593/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.8317e-05 - accuracy: 1.0000\n",
            "Epoch 594/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.8072e-05 - accuracy: 1.0000\n",
            "Epoch 595/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.7828e-05 - accuracy: 1.0000\n",
            "Epoch 596/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.7585e-05 - accuracy: 1.0000\n",
            "Epoch 597/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.7343e-05 - accuracy: 1.0000\n",
            "Epoch 598/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.7102e-05 - accuracy: 1.0000\n",
            "Epoch 599/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.6862e-05 - accuracy: 1.0000\n",
            "Epoch 600/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.6623e-05 - accuracy: 1.0000\n",
            "Epoch 601/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.6385e-05 - accuracy: 1.0000\n",
            "Epoch 602/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.6148e-05 - accuracy: 1.0000\n",
            "Epoch 603/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.5912e-05 - accuracy: 1.0000\n",
            "Epoch 604/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.5677e-05 - accuracy: 1.0000\n",
            "Epoch 605/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.5443e-05 - accuracy: 1.0000\n",
            "Epoch 606/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.5209e-05 - accuracy: 1.0000\n",
            "Epoch 607/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.4977e-05 - accuracy: 1.0000\n",
            "Epoch 608/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.4745e-05 - accuracy: 1.0000\n",
            "Epoch 609/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.4515e-05 - accuracy: 1.0000\n",
            "Epoch 610/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.4285e-05 - accuracy: 1.0000\n",
            "Epoch 611/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.4057e-05 - accuracy: 1.0000\n",
            "Epoch 612/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.3829e-05 - accuracy: 1.0000\n",
            "Epoch 613/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.3602e-05 - accuracy: 1.0000\n",
            "Epoch 614/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.3376e-05 - accuracy: 1.0000\n",
            "Epoch 615/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.3151e-05 - accuracy: 1.0000\n",
            "Epoch 616/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.2927e-05 - accuracy: 1.0000\n",
            "Epoch 617/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 8.2703e-05 - accuracy: 1.0000\n",
            "Epoch 618/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.2481e-05 - accuracy: 1.0000\n",
            "Epoch 619/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.2259e-05 - accuracy: 1.0000\n",
            "Epoch 620/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.2038e-05 - accuracy: 1.0000\n",
            "Epoch 621/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.1819e-05 - accuracy: 1.0000\n",
            "Epoch 622/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 8.1600e-05 - accuracy: 1.0000\n",
            "Epoch 623/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.1381e-05 - accuracy: 1.0000\n",
            "Epoch 624/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.1164e-05 - accuracy: 1.0000\n",
            "Epoch 625/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.0948e-05 - accuracy: 1.0000\n",
            "Epoch 626/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.0732e-05 - accuracy: 1.0000\n",
            "Epoch 627/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.0517e-05 - accuracy: 1.0000\n",
            "Epoch 628/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 8.0303e-05 - accuracy: 1.0000\n",
            "Epoch 629/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 8.0090e-05 - accuracy: 1.0000\n",
            "Epoch 630/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.9878e-05 - accuracy: 1.0000\n",
            "Epoch 631/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.9666e-05 - accuracy: 1.0000\n",
            "Epoch 632/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.9456e-05 - accuracy: 1.0000\n",
            "Epoch 633/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.9246e-05 - accuracy: 1.0000\n",
            "Epoch 634/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.9037e-05 - accuracy: 1.0000\n",
            "Epoch 635/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.8829e-05 - accuracy: 1.0000\n",
            "Epoch 636/1000\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 7.8621e-05 - accuracy: 1.0000\n",
            "Epoch 637/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.8414e-05 - accuracy: 1.0000\n",
            "Epoch 638/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.8209e-05 - accuracy: 1.0000\n",
            "Epoch 639/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.8003e-05 - accuracy: 1.0000\n",
            "Epoch 640/1000\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.7799e-05 - accuracy: 1.0000\n",
            "Epoch 641/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.7595e-05 - accuracy: 1.0000\n",
            "Epoch 642/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.7393e-05 - accuracy: 1.0000\n",
            "Epoch 643/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.7191e-05 - accuracy: 1.0000\n",
            "Epoch 644/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.6990e-05 - accuracy: 1.0000\n",
            "Epoch 645/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.6789e-05 - accuracy: 1.0000\n",
            "Epoch 646/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.6589e-05 - accuracy: 1.0000\n",
            "Epoch 647/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.6390e-05 - accuracy: 1.0000\n",
            "Epoch 648/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.6192e-05 - accuracy: 1.0000\n",
            "Epoch 649/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.5994e-05 - accuracy: 1.0000\n",
            "Epoch 650/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5798e-05 - accuracy: 1.0000\n",
            "Epoch 651/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.5602e-05 - accuracy: 1.0000\n",
            "Epoch 652/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5406e-05 - accuracy: 1.0000\n",
            "Epoch 653/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.5212e-05 - accuracy: 1.0000\n",
            "Epoch 654/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.5018e-05 - accuracy: 1.0000\n",
            "Epoch 655/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4825e-05 - accuracy: 1.0000\n",
            "Epoch 656/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4633e-05 - accuracy: 1.0000\n",
            "Epoch 657/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.4441e-05 - accuracy: 1.0000\n",
            "Epoch 658/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4250e-05 - accuracy: 1.0000\n",
            "Epoch 659/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.4060e-05 - accuracy: 1.0000\n",
            "Epoch 660/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.3870e-05 - accuracy: 1.0000\n",
            "Epoch 661/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3681e-05 - accuracy: 1.0000\n",
            "Epoch 662/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.3493e-05 - accuracy: 1.0000\n",
            "Epoch 663/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.3306e-05 - accuracy: 1.0000\n",
            "Epoch 664/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.3119e-05 - accuracy: 1.0000\n",
            "Epoch 665/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2933e-05 - accuracy: 1.0000\n",
            "Epoch 666/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.2747e-05 - accuracy: 1.0000\n",
            "Epoch 667/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2563e-05 - accuracy: 1.0000\n",
            "Epoch 668/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 7.2378e-05 - accuracy: 1.0000\n",
            "Epoch 669/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2195e-05 - accuracy: 1.0000\n",
            "Epoch 670/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.2013e-05 - accuracy: 1.0000\n",
            "Epoch 671/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 7.1830e-05 - accuracy: 1.0000\n",
            "Epoch 672/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1649e-05 - accuracy: 1.0000\n",
            "Epoch 673/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1468e-05 - accuracy: 1.0000\n",
            "Epoch 674/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.1288e-05 - accuracy: 1.0000\n",
            "Epoch 675/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.1109e-05 - accuracy: 1.0000\n",
            "Epoch 676/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0930e-05 - accuracy: 1.0000\n",
            "Epoch 677/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.0752e-05 - accuracy: 1.0000\n",
            "Epoch 678/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 7.0575e-05 - accuracy: 1.0000\n",
            "Epoch 679/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0398e-05 - accuracy: 1.0000\n",
            "Epoch 680/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0222e-05 - accuracy: 1.0000\n",
            "Epoch 681/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 7.0046e-05 - accuracy: 1.0000\n",
            "Epoch 682/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.9871e-05 - accuracy: 1.0000\n",
            "Epoch 683/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.9697e-05 - accuracy: 1.0000\n",
            "Epoch 684/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.9523e-05 - accuracy: 1.0000\n",
            "Epoch 685/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.9350e-05 - accuracy: 1.0000\n",
            "Epoch 686/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.9178e-05 - accuracy: 1.0000\n",
            "Epoch 687/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.9006e-05 - accuracy: 1.0000\n",
            "Epoch 688/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.8835e-05 - accuracy: 1.0000\n",
            "Epoch 689/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.8664e-05 - accuracy: 1.0000\n",
            "Epoch 690/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8494e-05 - accuracy: 1.0000\n",
            "Epoch 691/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.8325e-05 - accuracy: 1.0000\n",
            "Epoch 692/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.8156e-05 - accuracy: 1.0000\n",
            "Epoch 693/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7988e-05 - accuracy: 1.0000\n",
            "Epoch 694/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7820e-05 - accuracy: 1.0000\n",
            "Epoch 695/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7653e-05 - accuracy: 1.0000\n",
            "Epoch 696/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.7487e-05 - accuracy: 1.0000\n",
            "Epoch 697/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.7321e-05 - accuracy: 1.0000\n",
            "Epoch 698/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.7156e-05 - accuracy: 1.0000\n",
            "Epoch 699/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6991e-05 - accuracy: 1.0000\n",
            "Epoch 700/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.6827e-05 - accuracy: 1.0000\n",
            "Epoch 701/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.6663e-05 - accuracy: 1.0000\n",
            "Epoch 702/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6500e-05 - accuracy: 1.0000\n",
            "Epoch 703/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.6338e-05 - accuracy: 1.0000\n",
            "Epoch 704/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6176e-05 - accuracy: 1.0000\n",
            "Epoch 705/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.6015e-05 - accuracy: 1.0000\n",
            "Epoch 706/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5854e-05 - accuracy: 1.0000\n",
            "Epoch 707/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.5694e-05 - accuracy: 1.0000\n",
            "Epoch 708/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.5535e-05 - accuracy: 1.0000\n",
            "Epoch 709/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5376e-05 - accuracy: 1.0000\n",
            "Epoch 710/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.5217e-05 - accuracy: 1.0000\n",
            "Epoch 711/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.5059e-05 - accuracy: 1.0000\n",
            "Epoch 712/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.4902e-05 - accuracy: 1.0000\n",
            "Epoch 713/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.4745e-05 - accuracy: 1.0000\n",
            "Epoch 714/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.4589e-05 - accuracy: 1.0000\n",
            "Epoch 715/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.4433e-05 - accuracy: 1.0000\n",
            "Epoch 716/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4278e-05 - accuracy: 1.0000\n",
            "Epoch 717/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4123e-05 - accuracy: 1.0000\n",
            "Epoch 718/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3969e-05 - accuracy: 1.0000\n",
            "Epoch 719/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3815e-05 - accuracy: 1.0000\n",
            "Epoch 720/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.3663e-05 - accuracy: 1.0000\n",
            "Epoch 721/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.3510e-05 - accuracy: 1.0000\n",
            "Epoch 722/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.3358e-05 - accuracy: 1.0000\n",
            "Epoch 723/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3206e-05 - accuracy: 1.0000\n",
            "Epoch 724/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.3055e-05 - accuracy: 1.0000\n",
            "Epoch 725/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2905e-05 - accuracy: 1.0000\n",
            "Epoch 726/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2755e-05 - accuracy: 1.0000\n",
            "Epoch 727/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2606e-05 - accuracy: 1.0000\n",
            "Epoch 728/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2456e-05 - accuracy: 1.0000\n",
            "Epoch 729/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2308e-05 - accuracy: 1.0000\n",
            "Epoch 730/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.2160e-05 - accuracy: 1.0000\n",
            "Epoch 731/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.2013e-05 - accuracy: 1.0000\n",
            "Epoch 732/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.1866e-05 - accuracy: 1.0000\n",
            "Epoch 733/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.1719e-05 - accuracy: 1.0000\n",
            "Epoch 734/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.1573e-05 - accuracy: 1.0000\n",
            "Epoch 735/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.1428e-05 - accuracy: 1.0000\n",
            "Epoch 736/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.1283e-05 - accuracy: 1.0000\n",
            "Epoch 737/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.1138e-05 - accuracy: 1.0000\n",
            "Epoch 738/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.0994e-05 - accuracy: 1.0000\n",
            "Epoch 739/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.0851e-05 - accuracy: 1.0000\n",
            "Epoch 740/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.0708e-05 - accuracy: 1.0000\n",
            "Epoch 741/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.0565e-05 - accuracy: 1.0000\n",
            "Epoch 742/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 6.0423e-05 - accuracy: 1.0000\n",
            "Epoch 743/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 6.0281e-05 - accuracy: 1.0000\n",
            "Epoch 744/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.0140e-05 - accuracy: 1.0000\n",
            "Epoch 745/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9999e-05 - accuracy: 1.0000\n",
            "Epoch 746/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9859e-05 - accuracy: 1.0000\n",
            "Epoch 747/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9720e-05 - accuracy: 1.0000\n",
            "Epoch 748/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.9580e-05 - accuracy: 1.0000\n",
            "Epoch 749/1000\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.9441e-05 - accuracy: 1.0000\n",
            "Epoch 750/1000\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.9303e-05 - accuracy: 1.0000\n",
            "Epoch 751/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.9165e-05 - accuracy: 1.0000\n",
            "Epoch 752/1000\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 5.9028e-05 - accuracy: 1.0000\n",
            "Epoch 753/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8891e-05 - accuracy: 1.0000\n",
            "Epoch 754/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.8754e-05 - accuracy: 1.0000\n",
            "Epoch 755/1000\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 5.8618e-05 - accuracy: 1.0000\n",
            "Epoch 756/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.8482e-05 - accuracy: 1.0000\n",
            "Epoch 757/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.8347e-05 - accuracy: 1.0000\n",
            "Epoch 758/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.8212e-05 - accuracy: 1.0000\n",
            "Epoch 759/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.8078e-05 - accuracy: 1.0000\n",
            "Epoch 760/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.7944e-05 - accuracy: 1.0000\n",
            "Epoch 761/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.7811e-05 - accuracy: 1.0000\n",
            "Epoch 762/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.7678e-05 - accuracy: 1.0000\n",
            "Epoch 763/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.7545e-05 - accuracy: 1.0000\n",
            "Epoch 764/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.7413e-05 - accuracy: 1.0000\n",
            "Epoch 765/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.7281e-05 - accuracy: 1.0000\n",
            "Epoch 766/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.7150e-05 - accuracy: 1.0000\n",
            "Epoch 767/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.7019e-05 - accuracy: 1.0000\n",
            "Epoch 768/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.6888e-05 - accuracy: 1.0000\n",
            "Epoch 769/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.6758e-05 - accuracy: 1.0000\n",
            "Epoch 770/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.6629e-05 - accuracy: 1.0000\n",
            "Epoch 771/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.6500e-05 - accuracy: 1.0000\n",
            "Epoch 772/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.6371e-05 - accuracy: 1.0000\n",
            "Epoch 773/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.6243e-05 - accuracy: 1.0000\n",
            "Epoch 774/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.6114e-05 - accuracy: 1.0000\n",
            "Epoch 775/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.5987e-05 - accuracy: 1.0000\n",
            "Epoch 776/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.5860e-05 - accuracy: 1.0000\n",
            "Epoch 777/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.5733e-05 - accuracy: 1.0000\n",
            "Epoch 778/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.5607e-05 - accuracy: 1.0000\n",
            "Epoch 779/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.5481e-05 - accuracy: 1.0000\n",
            "Epoch 780/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.5355e-05 - accuracy: 1.0000\n",
            "Epoch 781/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.5230e-05 - accuracy: 1.0000\n",
            "Epoch 782/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.5105e-05 - accuracy: 1.0000\n",
            "Epoch 783/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.4981e-05 - accuracy: 1.0000\n",
            "Epoch 784/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.4857e-05 - accuracy: 1.0000\n",
            "Epoch 785/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.4734e-05 - accuracy: 1.0000\n",
            "Epoch 786/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.4610e-05 - accuracy: 1.0000\n",
            "Epoch 787/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.4488e-05 - accuracy: 1.0000\n",
            "Epoch 788/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.4366e-05 - accuracy: 1.0000\n",
            "Epoch 789/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.4244e-05 - accuracy: 1.0000\n",
            "Epoch 790/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.4122e-05 - accuracy: 1.0000\n",
            "Epoch 791/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.4001e-05 - accuracy: 1.0000\n",
            "Epoch 792/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.3880e-05 - accuracy: 1.0000\n",
            "Epoch 793/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3759e-05 - accuracy: 1.0000\n",
            "Epoch 794/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.3639e-05 - accuracy: 1.0000\n",
            "Epoch 795/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3520e-05 - accuracy: 1.0000\n",
            "Epoch 796/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3400e-05 - accuracy: 1.0000\n",
            "Epoch 797/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3281e-05 - accuracy: 1.0000\n",
            "Epoch 798/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3163e-05 - accuracy: 1.0000\n",
            "Epoch 799/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.3045e-05 - accuracy: 1.0000\n",
            "Epoch 800/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2927e-05 - accuracy: 1.0000\n",
            "Epoch 801/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2809e-05 - accuracy: 1.0000\n",
            "Epoch 802/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2692e-05 - accuracy: 1.0000\n",
            "Epoch 803/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2576e-05 - accuracy: 1.0000\n",
            "Epoch 804/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2459e-05 - accuracy: 1.0000\n",
            "Epoch 805/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2343e-05 - accuracy: 1.0000\n",
            "Epoch 806/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2227e-05 - accuracy: 1.0000\n",
            "Epoch 807/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.2112e-05 - accuracy: 1.0000\n",
            "Epoch 808/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.1997e-05 - accuracy: 1.0000\n",
            "Epoch 809/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1883e-05 - accuracy: 1.0000\n",
            "Epoch 810/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1768e-05 - accuracy: 1.0000\n",
            "Epoch 811/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1655e-05 - accuracy: 1.0000\n",
            "Epoch 812/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1541e-05 - accuracy: 1.0000\n",
            "Epoch 813/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1428e-05 - accuracy: 1.0000\n",
            "Epoch 814/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1315e-05 - accuracy: 1.0000\n",
            "Epoch 815/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.1203e-05 - accuracy: 1.0000\n",
            "Epoch 816/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.1091e-05 - accuracy: 1.0000\n",
            "Epoch 817/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.0979e-05 - accuracy: 1.0000\n",
            "Epoch 818/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.0867e-05 - accuracy: 1.0000\n",
            "Epoch 819/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.0756e-05 - accuracy: 1.0000\n",
            "Epoch 820/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.0646e-05 - accuracy: 1.0000\n",
            "Epoch 821/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.0535e-05 - accuracy: 1.0000\n",
            "Epoch 822/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.0425e-05 - accuracy: 1.0000\n",
            "Epoch 823/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.0315e-05 - accuracy: 1.0000\n",
            "Epoch 824/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 5.0206e-05 - accuracy: 1.0000\n",
            "Epoch 825/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 5.0097e-05 - accuracy: 1.0000\n",
            "Epoch 826/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.9988e-05 - accuracy: 1.0000\n",
            "Epoch 827/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.9880e-05 - accuracy: 1.0000\n",
            "Epoch 828/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.9771e-05 - accuracy: 1.0000\n",
            "Epoch 829/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.9664e-05 - accuracy: 1.0000\n",
            "Epoch 830/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.9556e-05 - accuracy: 1.0000\n",
            "Epoch 831/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.9449e-05 - accuracy: 1.0000\n",
            "Epoch 832/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.9342e-05 - accuracy: 1.0000\n",
            "Epoch 833/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.9236e-05 - accuracy: 1.0000\n",
            "Epoch 834/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.9130e-05 - accuracy: 1.0000\n",
            "Epoch 835/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.9024e-05 - accuracy: 1.0000\n",
            "Epoch 836/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.8918e-05 - accuracy: 1.0000\n",
            "Epoch 837/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.8813e-05 - accuracy: 1.0000\n",
            "Epoch 838/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.8708e-05 - accuracy: 1.0000\n",
            "Epoch 839/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.8604e-05 - accuracy: 1.0000\n",
            "Epoch 840/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.8499e-05 - accuracy: 1.0000\n",
            "Epoch 841/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.8395e-05 - accuracy: 1.0000\n",
            "Epoch 842/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.8292e-05 - accuracy: 1.0000\n",
            "Epoch 843/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.8189e-05 - accuracy: 1.0000\n",
            "Epoch 844/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.8086e-05 - accuracy: 1.0000\n",
            "Epoch 845/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.7983e-05 - accuracy: 1.0000\n",
            "Epoch 846/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.7880e-05 - accuracy: 1.0000\n",
            "Epoch 847/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.7778e-05 - accuracy: 1.0000\n",
            "Epoch 848/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.7677e-05 - accuracy: 1.0000\n",
            "Epoch 849/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.7575e-05 - accuracy: 1.0000\n",
            "Epoch 850/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.7474e-05 - accuracy: 1.0000\n",
            "Epoch 851/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.7373e-05 - accuracy: 1.0000\n",
            "Epoch 852/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.7272e-05 - accuracy: 1.0000\n",
            "Epoch 853/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.7172e-05 - accuracy: 1.0000\n",
            "Epoch 854/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.7072e-05 - accuracy: 1.0000\n",
            "Epoch 855/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.6972e-05 - accuracy: 1.0000\n",
            "Epoch 856/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.6873e-05 - accuracy: 1.0000\n",
            "Epoch 857/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.6774e-05 - accuracy: 1.0000\n",
            "Epoch 858/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.6675e-05 - accuracy: 1.0000\n",
            "Epoch 859/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.6577e-05 - accuracy: 1.0000\n",
            "Epoch 860/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.6478e-05 - accuracy: 1.0000\n",
            "Epoch 861/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.6380e-05 - accuracy: 1.0000\n",
            "Epoch 862/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.6283e-05 - accuracy: 1.0000\n",
            "Epoch 863/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.6185e-05 - accuracy: 1.0000\n",
            "Epoch 864/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.6088e-05 - accuracy: 1.0000\n",
            "Epoch 865/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5991e-05 - accuracy: 1.0000\n",
            "Epoch 866/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5895e-05 - accuracy: 1.0000\n",
            "Epoch 867/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5799e-05 - accuracy: 1.0000\n",
            "Epoch 868/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5703e-05 - accuracy: 1.0000\n",
            "Epoch 869/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5607e-05 - accuracy: 1.0000\n",
            "Epoch 870/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5511e-05 - accuracy: 1.0000\n",
            "Epoch 871/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5416e-05 - accuracy: 1.0000\n",
            "Epoch 872/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5321e-05 - accuracy: 1.0000\n",
            "Epoch 873/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5227e-05 - accuracy: 1.0000\n",
            "Epoch 874/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5133e-05 - accuracy: 1.0000\n",
            "Epoch 875/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.5038e-05 - accuracy: 1.0000\n",
            "Epoch 876/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.4945e-05 - accuracy: 1.0000\n",
            "Epoch 877/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.4851e-05 - accuracy: 1.0000\n",
            "Epoch 878/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.4758e-05 - accuracy: 1.0000\n",
            "Epoch 879/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.4665e-05 - accuracy: 1.0000\n",
            "Epoch 880/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.4572e-05 - accuracy: 1.0000\n",
            "Epoch 881/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.4480e-05 - accuracy: 1.0000\n",
            "Epoch 882/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.4388e-05 - accuracy: 1.0000\n",
            "Epoch 883/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.4296e-05 - accuracy: 1.0000\n",
            "Epoch 884/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.4204e-05 - accuracy: 1.0000\n",
            "Epoch 885/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.4113e-05 - accuracy: 1.0000\n",
            "Epoch 886/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.4022e-05 - accuracy: 1.0000\n",
            "Epoch 887/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.3931e-05 - accuracy: 1.0000\n",
            "Epoch 888/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.3840e-05 - accuracy: 1.0000\n",
            "Epoch 889/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.3750e-05 - accuracy: 1.0000\n",
            "Epoch 890/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.3660e-05 - accuracy: 1.0000\n",
            "Epoch 891/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.3570e-05 - accuracy: 1.0000\n",
            "Epoch 892/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.3480e-05 - accuracy: 1.0000\n",
            "Epoch 893/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.3391e-05 - accuracy: 1.0000\n",
            "Epoch 894/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.3302e-05 - accuracy: 1.0000\n",
            "Epoch 895/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.3213e-05 - accuracy: 1.0000\n",
            "Epoch 896/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.3125e-05 - accuracy: 1.0000\n",
            "Epoch 897/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.3036e-05 - accuracy: 1.0000\n",
            "Epoch 898/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.2948e-05 - accuracy: 1.0000\n",
            "Epoch 899/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2861e-05 - accuracy: 1.0000\n",
            "Epoch 900/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2773e-05 - accuracy: 1.0000\n",
            "Epoch 901/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2686e-05 - accuracy: 1.0000\n",
            "Epoch 902/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2599e-05 - accuracy: 1.0000\n",
            "Epoch 903/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2512e-05 - accuracy: 1.0000\n",
            "Epoch 904/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2425e-05 - accuracy: 1.0000\n",
            "Epoch 905/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2339e-05 - accuracy: 1.0000\n",
            "Epoch 906/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2253e-05 - accuracy: 1.0000\n",
            "Epoch 907/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2167e-05 - accuracy: 1.0000\n",
            "Epoch 908/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.2081e-05 - accuracy: 1.0000\n",
            "Epoch 909/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.1996e-05 - accuracy: 1.0000\n",
            "Epoch 910/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.1911e-05 - accuracy: 1.0000\n",
            "Epoch 911/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.1826e-05 - accuracy: 1.0000\n",
            "Epoch 912/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.1741e-05 - accuracy: 1.0000\n",
            "Epoch 913/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.1657e-05 - accuracy: 1.0000\n",
            "Epoch 914/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.1573e-05 - accuracy: 1.0000\n",
            "Epoch 915/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.1489e-05 - accuracy: 1.0000\n",
            "Epoch 916/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.1405e-05 - accuracy: 1.0000\n",
            "Epoch 917/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.1322e-05 - accuracy: 1.0000\n",
            "Epoch 918/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.1238e-05 - accuracy: 1.0000\n",
            "Epoch 919/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.1155e-05 - accuracy: 1.0000\n",
            "Epoch 920/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.1073e-05 - accuracy: 1.0000\n",
            "Epoch 921/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.0990e-05 - accuracy: 1.0000\n",
            "Epoch 922/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.0908e-05 - accuracy: 1.0000\n",
            "Epoch 923/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.0825e-05 - accuracy: 1.0000\n",
            "Epoch 924/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.0744e-05 - accuracy: 1.0000\n",
            "Epoch 925/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.0662e-05 - accuracy: 1.0000\n",
            "Epoch 926/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.0581e-05 - accuracy: 1.0000\n",
            "Epoch 927/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 4.0499e-05 - accuracy: 1.0000\n",
            "Epoch 928/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.0418e-05 - accuracy: 1.0000\n",
            "Epoch 929/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.0338e-05 - accuracy: 1.0000\n",
            "Epoch 930/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.0257e-05 - accuracy: 1.0000\n",
            "Epoch 931/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.0177e-05 - accuracy: 1.0000\n",
            "Epoch 932/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.0097e-05 - accuracy: 1.0000\n",
            "Epoch 933/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 4.0017e-05 - accuracy: 1.0000\n",
            "Epoch 934/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9937e-05 - accuracy: 1.0000\n",
            "Epoch 935/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9858e-05 - accuracy: 1.0000\n",
            "Epoch 936/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9779e-05 - accuracy: 1.0000\n",
            "Epoch 937/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9699e-05 - accuracy: 1.0000\n",
            "Epoch 938/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9621e-05 - accuracy: 1.0000\n",
            "Epoch 939/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9542e-05 - accuracy: 1.0000\n",
            "Epoch 940/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.9464e-05 - accuracy: 1.0000\n",
            "Epoch 941/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.9386e-05 - accuracy: 1.0000\n",
            "Epoch 942/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9308e-05 - accuracy: 1.0000\n",
            "Epoch 943/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.9230e-05 - accuracy: 1.0000\n",
            "Epoch 944/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.9152e-05 - accuracy: 1.0000\n",
            "Epoch 945/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.9075e-05 - accuracy: 1.0000\n",
            "Epoch 946/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8998e-05 - accuracy: 1.0000\n",
            "Epoch 947/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.8921e-05 - accuracy: 1.0000\n",
            "Epoch 948/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8844e-05 - accuracy: 1.0000\n",
            "Epoch 949/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8768e-05 - accuracy: 1.0000\n",
            "Epoch 950/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8692e-05 - accuracy: 1.0000\n",
            "Epoch 951/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8616e-05 - accuracy: 1.0000\n",
            "Epoch 952/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.8540e-05 - accuracy: 1.0000\n",
            "Epoch 953/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8464e-05 - accuracy: 1.0000\n",
            "Epoch 954/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.8389e-05 - accuracy: 1.0000\n",
            "Epoch 955/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.8313e-05 - accuracy: 1.0000\n",
            "Epoch 956/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.8238e-05 - accuracy: 1.0000\n",
            "Epoch 957/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.8163e-05 - accuracy: 1.0000\n",
            "Epoch 958/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.8089e-05 - accuracy: 1.0000\n",
            "Epoch 959/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.8014e-05 - accuracy: 1.0000\n",
            "Epoch 960/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7940e-05 - accuracy: 1.0000\n",
            "Epoch 961/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7866e-05 - accuracy: 1.0000\n",
            "Epoch 962/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7792e-05 - accuracy: 1.0000\n",
            "Epoch 963/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7719e-05 - accuracy: 1.0000\n",
            "Epoch 964/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7645e-05 - accuracy: 1.0000\n",
            "Epoch 965/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7572e-05 - accuracy: 1.0000\n",
            "Epoch 966/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7499e-05 - accuracy: 1.0000\n",
            "Epoch 967/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7426e-05 - accuracy: 1.0000\n",
            "Epoch 968/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7353e-05 - accuracy: 1.0000\n",
            "Epoch 969/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.7281e-05 - accuracy: 1.0000\n",
            "Epoch 970/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.7208e-05 - accuracy: 1.0000\n",
            "Epoch 971/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7136e-05 - accuracy: 1.0000\n",
            "Epoch 972/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.7064e-05 - accuracy: 1.0000\n",
            "Epoch 973/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6993e-05 - accuracy: 1.0000\n",
            "Epoch 974/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6921e-05 - accuracy: 1.0000\n",
            "Epoch 975/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6850e-05 - accuracy: 1.0000\n",
            "Epoch 976/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6779e-05 - accuracy: 1.0000\n",
            "Epoch 977/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6708e-05 - accuracy: 1.0000\n",
            "Epoch 978/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6637e-05 - accuracy: 1.0000\n",
            "Epoch 979/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6566e-05 - accuracy: 1.0000\n",
            "Epoch 980/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6496e-05 - accuracy: 1.0000\n",
            "Epoch 981/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.6426e-05 - accuracy: 1.0000\n",
            "Epoch 982/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6355e-05 - accuracy: 1.0000\n",
            "Epoch 983/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6286e-05 - accuracy: 1.0000\n",
            "Epoch 984/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.6216e-05 - accuracy: 1.0000\n",
            "Epoch 985/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6146e-05 - accuracy: 1.0000\n",
            "Epoch 986/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.6077e-05 - accuracy: 1.0000\n",
            "Epoch 987/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.6008e-05 - accuracy: 1.0000\n",
            "Epoch 988/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5939e-05 - accuracy: 1.0000\n",
            "Epoch 989/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5870e-05 - accuracy: 1.0000\n",
            "Epoch 990/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5802e-05 - accuracy: 1.0000\n",
            "Epoch 991/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.5733e-05 - accuracy: 1.0000\n",
            "Epoch 992/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5665e-05 - accuracy: 1.0000\n",
            "Epoch 993/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5597e-05 - accuracy: 1.0000\n",
            "Epoch 994/1000\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 3.5529e-05 - accuracy: 1.0000\n",
            "Epoch 995/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5461e-05 - accuracy: 1.0000\n",
            "Epoch 996/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5394e-05 - accuracy: 1.0000\n",
            "Epoch 997/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5326e-05 - accuracy: 1.0000\n",
            "Epoch 998/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5259e-05 - accuracy: 1.0000\n",
            "Epoch 999/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5192e-05 - accuracy: 1.0000\n",
            "Epoch 1000/1000\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 3.5125e-05 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize training process\n",
        "plt.plot(history.history['loss'], label='Mean Squarred Error loss, learning rate : 0.5 (training data)')\n",
        "#plt.plot(history.history['accuracy'], label='accuracy (training data)')\n",
        "plt.title('Mean Squarred Loss')\n",
        "plt.ylabel('loss value')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "YdFW8xCU7MCn",
        "outputId": "9bba0f31-8129-43b7-aa13-7385141b92dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqlUlEQVR4nO3deVhUZf8G8HvYBhCGfZVVFAUXcEXcTcyl3CottcI1S33NNEvffrlkZmWZlaQtb1pWappZmTulJm64gAsooCioLLLv28zz+wOZHAEFHDgD3J/r4so558yZ7zkNMzfP85znyIQQAkRERETNkJ7UBRARERFJhUGIiIiImi0GISIiImq2GISIiIio2WIQIiIiomaLQYiIiIiaLQYhIiIiarYYhIiIiKjZYhAiIiKiZotBiIhIR8lkMixdulTqMoiaNAYhokZo48aNkMlkkMlkOHr0aKX1Qgi4urpCJpPhySeflKDCmispKcGnn36Kzp07Q6FQwNLSEu3bt8dLL72Ey5cvS12ezrt+/TpkMhk++ugjqUshapQMpC6AiOrO2NgYP/30E/r06aOx/PDhw7h58ybkcrlEldXc008/jT179mD8+PGYPn06SktLcfnyZezatQu9evVCu3btpC6RiJowBiGiRmz48OHYtm0bPvvsMxgY/Pvr/NNPP6Fr165IS0uTsLqHCw8Px65du7BixQr897//1Vi3du1aZGVlSVNYDeTn56NFixZVrisoKICpqWkDV0REdcGuMaJGbPz48UhPT8eBAwfUy0pKSrB9+3ZMmDChyueoVCqsWbMG7du3h7GxMRwcHDBjxgxkZmZqbPfbb7/hiSeegLOzM+RyOby8vLB8+XIolUqN7QYMGIAOHTogKioKAwcOhKmpKVq2bIkPP/zwofVfvXoVANC7d+9K6/T19WFjY6Ox7OjRo+jevTuMjY3h5eWFL7/8EkuXLoVMJlNvU9FVtHHjxkr7vH/MzY0bNzBz5ky0bdsWJiYmsLGxwdixY3H9+nWN51V0RR4+fBgzZ86Evb09XFxcNI7/zJkz6NevH0xNTdWhrri4GEuWLEHr1q0hl8vh6uqKN954A8XFxRr7Ly4uxmuvvQY7OzuYm5tj5MiRuHnz5kPPX22kpqZi6tSpcHBwgLGxMfz8/PDdd99V2m7Lli3o2rUrzM3NoVAo0LFjR3z66afq9aWlpVi2bBnatGkDY2Nj2NjYoE+fPhrvQaLGhC1CRI2Yh4cHAgMDsXnzZgwbNgwAsGfPHmRnZ+O5557DZ599Vuk5M2bMwMaNGzF58mTMmTMH8fHxWLt2Lc6dO4ewsDAYGhoCKP/yNzMzw7x582BmZoa//voLixcvRk5ODlatWqWxz8zMTAwdOhRPPfUUxo0bh+3bt+PNN99Ex44d1XVVxd3dHQDw448/onfv3hqtWve7cOECHn/8cdjZ2WHp0qUoKyvDkiVL4ODgUOvzViE8PBzHjh3Dc889BxcXF1y/fh3r1q3DgAEDEBUVValVZ+bMmbCzs8PixYuRn5+vXp6eno5hw4bhueeew/PPPw8HBweoVCqMHDkSR48exUsvvQQfHx9cuHABn3zyCWJiYrBz507186dNm4YffvgBEyZMQK9evfDXX3/hiSeeqPNx3a+wsBADBgxAXFwcZs+eDU9PT2zbtg2TJk1CVlYWXn31VQDAgQMHMH78eAwaNAgffPABACA6OhphYWHqbZYuXYqVK1di2rRp6NGjB3JycnD69GmcPXsWgwcP1lrNRA1GEFGjs2HDBgFAhIeHi7Vr1wpzc3NRUFAghBBi7NixYuDAgUIIIdzd3cUTTzyhft4///wjAIgff/xRY3979+6ttLxif/eaMWOGMDU1FUVFRepl/fv3FwDE999/r15WXFwsHB0dxdNPP/3A41CpVOrnOzg4iPHjx4uQkBBx48aNStuOHj1aGBsba6yLiooS+vr64t6Psvj4eAFAbNiwodI+AIglS5Y88BiPHz9e6XgqznefPn1EWVmZxvYV9a9fv15j+aZNm4Senp74559/NJavX79eABBhYWFCCCEiIiIEADFz5kyN7SZMmFCp3qpUHO+qVauq3WbNmjUCgPjhhx/Uy0pKSkRgYKAwMzMTOTk5QgghXn31VaFQKCod4738/Pw03lNEjR27xogauXHjxqGwsBC7du1Cbm4udu3aVW232LZt22BhYYHBgwcjLS1N/dO1a1eYmZnh77//Vm9rYmKi/ndubi7S0tLQt29fFBQUVLqay8zMDM8//7z6sZGREXr06IFr1649sHaZTIZ9+/bh3XffhZWVFTZv3oxZs2bB3d0dzz77rHqMkFKpxL59+zB69Gi4ubmpn+/j44MhQ4bU+Fzd795jLC0tRXp6Olq3bg1LS0ucPXu20vbTp0+Hvr5+peVyuRyTJ0/WWLZt2zb4+PigXbt2Guf6scceAwD1ud69ezcAYM6cORrPnzt3bp2P6367d++Go6Mjxo8fr15maGiIOXPmIC8vD4cPHwYAWFpaIj8//4HdXJaWlrh06RJiY2O1Vh+RlBiEiBo5Ozs7BAUF4aeffsKOHTugVCrxzDPPVLltbGwssrOzYW9vDzs7O42fvLw8pKamqre9dOkSxowZAwsLCygUCtjZ2anDTnZ2tsZ+XVxcNMbpAICVlVWlcUdVkcvleOuttxAdHY3bt29j8+bN6NmzJ37++WfMnj0bAHDnzh0UFhaiTZs2lZ7ftm3bh75GdQoLC7F48WK4urpCLpfD1tYWdnZ2yMrKqnSMAODp6Vnlflq2bAkjIyONZbGxsbh06VKl8+zt7Q0A6nN948YN6OnpwcvLS2vHdb8bN26gTZs20NPT/Mj38fFRrwfKu/68vb0xbNgwuLi4YMqUKdi7d6/Gc9555x1kZWXB29sbHTt2xIIFC3D+/Hmt1UrU0DhGiKgJmDBhAqZPn47k5GQMGzYMlpaWVW6nUqlgb2+PH3/8scr1dnZ2AICsrCz0798fCoUC77zzDry8vGBsbIyzZ8/izTffhEql0nheVa0kQPl8RrXh5OSE5557Dk8//TTat2+Pn3/+ucpBzw9yfyCrcP8gbwD4z3/+gw0bNmDu3LkIDAyEhYUFZDIZnnvuuUrHCGi2ID1suUqlQseOHbF69eoqn+Pq6vqgw5CEvb09IiIisG/fPuzZswd79uzBhg0b8OKLL6oHVvfr1w9Xr17Fb7/9hv379+Obb77BJ598gvXr12PatGkSHwFR7TEIETUBY8aMwYwZM3DixAls3bq12u28vLxw8OBB9O7du9ovdQA4dOgQ0tPTsWPHDvTr10+9PD4+Xqt1V8fQ0BCdOnVCbGws0tLSYGdnBxMTkyq7Y65cuaLx2MrKCgAqXXpf0epxr+3btyM4OBgff/yxellRUZFWLtv38vJCZGQkBg0aVG04A8oHjKtUKly9elWjFej+43oU7u7uOH/+PFQqlUarUEUXZ8WgdaC8W3PEiBEYMWIEVCoVZs6ciS+//BJvv/02WrduDQCwtrbG5MmTMXnyZOTl5aFfv35YunQpgxA1SuwaI2oCzMzMsG7dOixduhQjRoyodrtx48ZBqVRi+fLlldaVlZWpA0BFC8+9LTolJSX44osvtFp3bGwsEhISKi3PysrC8ePHYWVlBTs7O+jr62PIkCHYuXOnxvbR0dHYt2+fxnMVCgVsbW1x5MgRjeVV1a6vr1+p1erzzz+vsvWotsaNG4dbt27h66+/rrSusLBQfdVZxVV191/ht2bNmkeuocLw4cORnJysEZLLysrw+eefw8zMDP379wdQfvXbvfT09NCpUycAUF/yf/82ZmZmaN26daUpAYgaC7YIETURwcHBD92mf//+mDFjBlauXImIiAg8/vjjMDQ0RGxsLLZt24ZPP/0UzzzzDHr16gUrKysEBwdjzpw5kMlk2LRpU627uh4mMjISEyZMwLBhw9C3b19YW1vj1q1b+O6773D79m2sWbNGHcqWLVuGvXv3om/fvpg5c6b6i7x9+/aVxqhMmzYN77//PqZNm4Zu3brhyJEjiImJqfT6Tz75JDZt2gQLCwv4+vri+PHjOHjwYKX5i+rihRdewM8//4yXX34Zf//9N3r37g2lUonLly/j559/xr59+9CtWzf4+/tj/Pjx+OKLL5CdnY1evXohNDQUcXFxtXq90NBQFBUVVVo+evRovPTSS/jyyy8xadIknDlzBh4eHti+fTvCwsKwZs0amJubAyg/bxkZGXjsscfg4uKCGzdu4PPPP4e/v796PJGvry8GDBiArl27wtraGqdPn8b27dvV47mIGh1pL1ojorq49/L5B7n/8vkKX331lejataswMTER5ubmomPHjuKNN94Qt2/fVm8TFhYmevbsKUxMTISzs7N44403xL59+wQA8ffff6u369+/v2jfvn2l1wgODhbu7u4PrC8lJUW8//77on///sLJyUkYGBgIKysr8dhjj4nt27dX2v7w4cOia9euwsjISLRq1UqsX79eLFmyRNz/UVZQUCCmTp0qLCwshLm5uRg3bpxITU2tdDl6ZmammDx5srC1tRVmZmZiyJAh4vLly8Ld3V0EBwert3vQ+a7u+IUov0T9gw8+EO3btxdyuVxYWVmJrl27imXLlons7Gz1doWFhWLOnDnCxsZGtGjRQowYMUIkJibW6vL56n42bdqkPtcVx2pkZCQ6duxYaYqB7du3i8cff1zY29sLIyMj4ebmJmbMmCGSkpLU27z77ruiR48ewtLSUpiYmIh27dqJFStWiJKSkgfWSaSrZEJo+U88IqIGtHTpUixbtkzrrVVE1DxwjBARERE1WwxCRERE1GwxCBEREVGzxTFCRERE1GyxRYiIiIiaLQYhIiIiarY4oeJDqFQq3L59G+bm5g+cJp+IiIh0hxACubm5cHZ2rnTD4XsxCD3E7du3dfLmiERERPRwiYmJcHFxqXY9g9BDVEw9n5iYCIVCIXE1REREVBM5OTlwdXVVf49Xh0HoISq6wxQKBYMQERFRI/OwYS0cLE1ERETNFoMQERERNVsMQkRERNRscYyQFqhUKpSUlEhdBhERkc4zMjJ64OXsDY1B6BGVlJQgPj4eKpVK6lKIiIh0np6eHjw9PWFkZCR1KQAYhB6JEAJJSUnQ19eHq6urTiVcIiIiXVMxSXFSUhLc3Nx0YqJiBqFHUFZWhoKCAjg7O8PU1FTqcoiIiHSenZ0dbt++jbKyMhgaGkpdDgdLVyckJAS+vr7o3r17tdsolUoA0JnmPSIiIl1X8Z1Z8R0qNQahasyaNQtRUVEIDw9/6La60LRHRETUGOjadyaDEBERETVbDEJEOkImk2Hnzp1Sl1FrGzduhKWlpdRlqOnSeRwwYADmzp0rdRnN0pUrV+Do6Ijc3Nx62f/SpUvh7+9fq+d4eHhgzZo19VLPwzTU78XevXvh7+/fqK6kZhBqhiZNmgSZTIaXX3650rpZs2ZBJpNh0qRJDV/YfZRKJd5//320a9cOJiYmsLa2RkBAAL755hupS5NExf+3+3+GDh0qdWlUjR07dmD58uVSl1GtunyZP4qMjAxMnDgRCoUClpaWmDp1KvLy8h74nAEDBlR6z1f12XW/RYsW4T//+Y/6hpvaDuyvv/46QkNDa/Wc8PBwvPTSS1qroT7V9b0xdOhQGBoa4scff9R+UfWEQUgiZUoVSsqUUKqEJK/v6uqKLVu2oLCwUL2sqKgIP/30E9zc3CSp6X7Lli3DJ598guXLlyMqKgp///03XnrpJWRlZUldWrUTaJaWltbr6w4dOhRJSUkaP5s3b652+6rqqevkn5w09F81/f9sbW390Dtf1wdd/X81ceJEXLp0CQcOHMCuXbtw5MiRGgWD6dOna7znP/zwwwdun5CQgF27dtXpD7qanjszMzPY2NjUat92dnbN4grjSZMm4bPPPpO6jBpjEJJIQkYBLifnIreofr84q9OlSxe4urpix44d6mU7duyAm5sbOnfurLGtSqXCypUr4enpCRMTE/j5+WH79u3q9UqlElOnTlWvb9u2LT799FONfUyaNAmjR4/GRx99BCcnJ9jY2GDWrFkP/EL5/fffMXPmTIwdOxaenp7w8/PD1KlT8frrr6u3yc/Px4svvggzMzM4OTnh448/rtQdUVWTsKWlJTZu3Kh+/Oabb8Lb2xumpqZo1aoV3n77bY3aKv46+uabb+Dp6QljY2P1vtetW4eRI0eiRYsWWLFiBQDgt99+Q5cuXWBsbIxWrVph2bJlKCsrU+8vNjYW/fr1g7GxMXx9fXHgwIFqz8O95HI5HB0dNX6srKw0jvX+eqqrPSEhAaNGjYKZmRkUCgXGjRuHlJSUhx5zTaxbtw5eXl4wMjJC27ZtsWnTJvU6IQSWLl0KNzc3yOVyODs7Y86cOer1X3zxBdq0aQNjY2M4ODjgmWeeqfHrViUxMRHjxo2DpaUlrK2tMWrUKFy/fl29Pjw8HIMHD4atrS0sLCzQv39/nD17VmMfDzqvmzZtgoeHBywsLPDcc89pdMXc/1708PDAe++9hylTpsDc3Bxubm746quvNF7r2LFj8Pf3h7GxMbp164adO3dCJpMhIiKi2mP08PDA8uXL8eKLL0KhUKjDxYPe1xs3bsSyZcsQGRmpbmmp+J3IysrCtGnTYGdnB4VCgcceewyRkZF1OPv/io6Oxt69e/HNN98gICAAffr0weeff44tW7bg9u3bD3yuqampxnteoVA8cPuff/4Zfn5+aNmyJQDg0KFDmDx5MrKzs9XHunTpUgB1O3dA5RaTmnzG3d81JpPJ8M0332DMmDEwNTVFmzZt8Pvvv2scy++//67+fRg4cCC+++47yGSyB/5BWJPPl7q+N1avXo2OHTuiRYsWcHV1xcyZMyu16o0YMQKnT5/G1atXq61Rpwh6oOzsbAFAZGdnV1pXWFgooqKiRGFhoRBCCJVKJfKLS2v0c+lWtjh5LU3czCio8XMe9KNSqWp8TMHBwWLUqFFi9erVYtCgQerlgwYNEp988okYNWqUCA4OVi9/9913Rbt27cTevXvF1atXxYYNG4RcLheHDh0SQghRUlIiFi9eLMLDw8W1a9fEDz/8IExNTcXWrVs1XlOhUIiXX35ZREdHiz/++EOYmpqKr776qto6hwwZIvr16ydSU1Or3eaVV14Rbm5u4uDBg+L8+fPiySefFObm5uLVV19VbwNA/PrrrxrPs7CwEBs2bFA/Xr58uQgLCxPx8fHi999/Fw4ODuKDDz5Qr1+yZIlo0aKFGDp0qDh79qyIjIxU79ve3l58++234urVq+LGjRviyJEjQqFQiI0bN4qrV6+K/fv3Cw8PD7F06VIhhBBKpVJ06NBBDBo0SERERIjDhw+Lzp07V1nnvSr+vz1IVfVUVbtSqRT+/v6iT58+4vTp0+LEiROia9euon///g895vtt2LBBWFhYqB/v2LFDGBoaipCQEHHlyhXx8ccfC319ffHXX38JIYTYtm2bUCgUYvfu3eLGjRvi5MmT6vdBeHi40NfXFz/99JO4fv26OHv2rPj0008feMxVnYOK81hSUiJ8fHzElClTxPnz50VUVJSYMGGCaNu2rSguLhZCCBEaGio2bdokoqOjRVRUlJg6dapwcHAQOTk5Dz2vZmZm4qmnnhIXLlwQR44cEY6OjuK///2v+nn9+/fXeC+6u7sLa2trERISImJjY8XKlSuFnp6euHz5shCi/PPG2tpaPP/88+LSpUti9+7dwtvbWwAQ586dq/aY3d3dhUKhEB999JGIi4sTcXFxQogHv68LCgrE/PnzRfv27UVSUpJISkoSBQUFQgghgoKCxIgRI0R4eLiIiYkR8+fPFzY2NiI9Pb3aGvr376/xuXG///3vf8LS0lJjWWlpqdDX1xc7dux44H5tbW2FjY2NaN++vVi4cKHIz8+vdnshhBg5cqR4+eWX1Y+Li4vFmjVrhEKhUB9rbm5unc+dEOW/H35+furHNfmMc3d3F5988on6MQDh4uIifvrpJxEbGyvmzJkjzMzM1Of52rVrwtDQULz++uvi8uXLYvPmzaJly5YCgMjMzKzy2Gv6+VLX98Ynn3wi/vrrLxEfHy9CQ0NF27ZtxSuvvFKpDgcHB43P2Hvd/91ZXx70/X0vBqGHqE0Qyi8uFe5v7pLkJ7+4tMbHVPGFmpqaKuRyubh+/bq4fv26MDY2Fnfu3NEIQkVFRcLU1FQcO3ZMYx9Tp04V48ePr/Y1Zs2aJZ5++mmN13R3dxdlZWXqZWPHjhXPPvtstfu4dOmS8PHxEXp6eqJjx45ixowZYvfu3er1ubm5wsjISPz888/qZenp6cLExKTWQeh+q1atEl27dlU/XrJkiTA0NKwUygCIuXPnaiwbNGiQeO+99zSWbdq0STg5OQkhhNi3b58wMDAQt27dUq/fs2dPjYKQvr6+aNGihcbPihUrHlhPVbXv379f6Ovri4SEBPWyS5cuCQDi1KlTDzzm+90fhHr16iWmT5+usc3YsWPF8OHDhRBCfPzxx8Lb21uUlJRU2tcvv/wiFAqFRgiprXvP46ZNm0Tbtm01/lAoLi4WJiYmYt++fVU+X6lUCnNzc/HHH39o7LOq82pqaqpR64IFC0RAQID6cVVB6Pnnn1c/VqlUwt7eXqxbt04IIcS6deuEjY2NxhfE119/XaMgNHr06GrXV6jqfX3vl7kQQvzzzz9CoVCIoqIijeVeXl7iyy+/rHbfL7zwgli4cGG161esWCG8vb0rLbezsxNffPFFtc/78ssvxd69e8X58+fFDz/8IFq2bCnGjBlT7fZCCOHn5yfeeecdjWX3v08raOvc1eQzrqog9H//93/qx3l5eQKA2LNnjxBCiDfffFN06NBBo4633nrrgUGorp8vNXlvVGXbtm3Cxsam0vLOnTur//i7n64FIc4s3YzZ2dnhiSeewMaNGyGEwBNPPAFbW1uNbeLi4lBQUIDBgwdrLC8pKdHoQgsJCcG3336LhIQEFBYWoqSkpNJAu/bt20NfX1/92MnJCRcuXKi2Pl9fX1y8eBFnzpxBWFgYjhw5ghEjRmDSpEn45ptvcPXqVZSUlCAgIED9HGtra7Rt27bW52Lr1q347LPPcPXqVeTl5aGsrKxS87u7uzvs7OwqPbdbt24ajyMjIxEWFqbuJgPKuw+LiopQUFCA6OhouLq6wtnZWb0+MDCwRnUOHDgQ69at01hmbW39wHqqqr2iBldXV/UyX19fWFpaIjo6Wj2RaHXH/CDR0dGVxn307t1b3V06duxYrFmzBq1atcLQoUMxfPhwjBgxAgYGBhg8eDDc3d3V64YOHaruNqiLyMhIxMXFVRqnU1RUpG62T0lJwf/93//h0KFDSE1NhVKpREFBARISEjSeU9V59fDw0Ni3k5MTUlNTH1hTp06d1P+WyWRwdHRUP+fKlSvo1KmTRjdkjx49anSsVdVXk/f1/SIjI5GXl1dp/EthYeEDuzq+//77GtVZW/e+lzp27AgnJycMGjQIV69ehZeXV5XPKSwsrFVXrrbOXW0/4wDN90OLFi2gUCg03g/3T+r7sPdDTT9f6nJ8AHDw4EGsXLkSly9fRk5ODsrKytSfbff+npqYmKCgoOCh+9MFDEJaZGKoj6h3htRo21uZhcgsKIG9uTHsFXKtvHZdTJkyBbNnzwZQHmbuV9H3++eff6r72yvI5eV1b9myBa+//jo+/vhjBAYGwtzcHKtWrcLJkyc1tr9/KnWZTPbQSyz19PTQvXt3dO/eHXPnzsUPP/yAF154AW+99VaNj1Emk0EIzUHp9/bbHz9+HBMnTsSyZcswZMgQWFhYYMuWLfj44481ntOiRYsq93//8ry8PCxbtgxPPfVUpW1r8+Fc3Wu1bt36odvUZFlNX0/bXF1dceXKFRw8eBAHDhzAzJkzsWrVKhw+fBjm5uY4e/YsDh06hP3792Px4sVYunQpwsPD63TFT15eHrp27VrlFSwVAS84OBjp6en49NNP4e7uDrlcjsDAwEqDZqs6F3V5T9flOTVxf301fV/fLy8vD05OTjh06FCldY9y1dW9ga9CWVkZMjIy4OjoWOP9VPzhExcXV20QsrW1RWZmZo33qa1zp0vvhwep6/Fdv34dTz75JF555RWsWLEC1tbWOHr0KKZOnYqSkhKNIJSRkVHrP6KkwiCkRTKZDKZGNTulLeQGKCxVwthQv8bPqQ9Dhw5FSUkJZDIZhgypHOJ8fX0hl8uRkJCA/v37V7mPsLAw9OrVCzNnzlQvq69Bcr6+vgDKB0l7eXnB0NAQJ0+eVF/plpmZiZiYGI1a7ezskJSUpH4cGxur8ZfKsWPH4O7urhGubty4Uecau3TpgitXrlQbWHx8fJCYmIikpCQ4OTkBAE6cOFHn16uLihoSExPVrUJRUVHIyspSn+NH2XdYWBiCg4PVy8LCwjT2a2JighEjRmDEiBGYNWsW2rVrhwsXLqBLly4wMDBAUFAQgoKCsGTJElhaWuKvv/6qMlg+TJcuXbB161bY29tX+9duWFgYvvjiCwwfPhxA+eDqtLS0Wr+WNrRt2xY//PADiouL1X9o1GR2+6rU5H1tZGRU6TYHXbp0QXJyMgwMDODh4VGn165KYGAgsrKycObMGXTt2hUA8Ndff0GlUmm06j5MxaDxit+dqnTu3BlRUVEay6o61upo+zOhrtq2bYvdu3drLHvY+6Emny91fW+cOXMGKpUKH3/8sfom4z///HOlGipaXO+/8EZXMQhJpGKGcZWQ5vL5Cvr6+oiOjlb/+37m5uZ4/fXX8dprr0GlUqFPnz7Izs5GWFgYFAoFgoOD0aZNG3z//ffYt28fPD09sWnTJoSHh8PT0/ORanvmmWfQu3dv9OrVC46OjoiPj8eiRYvg7e2Ndu3awcDAAFOnTsWCBQtgY2MDe3t7vPXWW+pf0AqPPfYY1q5di8DAQCiVSrz55psaf4W1adMGCQkJ2LJlC7p3744///wTv/76a53rXrx4MZ588km4ubnhmWeegZ6eHiIjI3Hx4kW8++67CAoKgre3N4KDg7Fq1Srk5OTUuIWruLgYycnJGssMDAwqdWk+TFBQEDp27IiJEydizZo1KCsrw8yZM9G/f/8quwlqY8GCBRg3bhw6d+6MoKAg/PHHH9ixYwcOHjwIoPyKFKVSiYCAAJiamuKHH36AiYkJ3N3dsWvXLly7dg39+vWDlZUVdu/eDZVKVafuTqD8cu1Vq1Zh1KhReOedd+Di4oIbN25gx44deOONN+Di4oI2bdpg06ZN6NatG3JycrBgwQKYmJg80jmoqwkTJuCtt97CSy+9hIULFyIhIQEfffQRgNrflqAm72sPDw/Ex8cjIiICLi4uMDc3R1BQEAIDAzF69Gh8+OGH8Pb2xu3bt/Hnn39izJgx1b4/XnzxRbRs2RIrV66scr2Pjw+GDh2K6dOnY/369SgtLcXs2bPx3HPPqbtxbt26hUGDBuH7779Hjx49cPXqVfz0008YPnw4bGxscP78ebz22mvo16+fRpfS/YYMGYJp06ZBqVSqP9c8PDyQl5eH0NBQ+Pn5wdTUtNouV21/JtTVjBkzsHr1arz55puYOnUqIiIi1FdvVfd+qMnnS13fG61bt0ZpaSk+//xzjBgxAmFhYVi/fn2lGk6cOKFuWW0MePm8RCrexPd32UhBoVA8sG94+fLlePvtt7Fy5Ur1h9mff/6pDjozZszAU089hWeffRYBAQFIT0/XaB2qqyFDhuCPP/7AiBEj1L/Y7dq1w/79+2FgUJ7hV61ahb59+2LEiBEICgpCnz591H9tVvj444/h6uqKvn37YsKECXj99dc1PgBHjhyJ1157DbNnz4a/vz+OHTuGt99++5Hq3rVrF/bv34/u3bujZ8+e+OSTT+Du7g6gvLvv119/RWFhIXr06IFp06ZpjCd6kL1798LJyUnjp0+fPrWuUSaT4bfffoOVlRX69euHoKAgtGrVClu3bq31vu43evRofPrpp/joo4/Qvn17fPnll9iwYQMGDBgAoLx75euvv0bv3r3RqVMnHDx4EH/88QdsbGxgaWmJHTt24LHHHoOPjw/Wr1+PzZs3o3379gDKQ1RtAoGpqSmOHDkCNzc3PPXUU/Dx8cHUqVNRVFSkfs//73//Q2ZmJrp06YIXXngBc+bMgb29/SOfh7pQKBT4448/EBERAX9/f7z11ltYvHgxgNp3q9bkff30009j6NChGDhwIOzs7LB582bIZDLs3r0b/fr1w+TJk+Ht7Y3nnnsON27cgIODQ7Wvl5CQoNHyWpUff/wR7dq1w6BBgzB8+HD06dNHY/qA0tJSXLlyRd1ia2RkhIMHD+Lxxx9Hu3btMH/+fDz99NP4448/Hvg6w4YNg4GBgTp8A0CvXr3w8ssv49lnn4Wdnd0D5yLS9mdCXXl6emL79u3YsWMHOnXqhHXr1qlDTUWL4f1q8vlS1/eGn58fVq9ejQ8++AAdOnTAjz/+WGXw3bx5MyZOnNho5kySCV34JtZhOTk5sLCwQHZ2dqWwUFRUhPj4+FrPsQIAqblFSM4ugpWpEVytG8ebpbEYMGAA/P39JZvKnurPkiVLcPjw4SrHrzRVP/74o3oOHKlaqhqjkJAQ/P7779i3b5/UpWjVihUrsH79eiQmJkpdSpXS0tLQtm1bnD59utpegUf57qyNB31/34tdY9UICQlBSEhIjfuUa0sPFS1C9bJ7oiZpz549WLt2rdRl1Kvvv/8erVq1QsuWLREZGYk333wT48aNYwiqpRkzZiArKwu5ubmSzO6tLV988QW6d+8OGxsbhIWFYdWqVeoLXHTR9evX8cUXXzzy0IiGxCBUjVmzZmHWrFnqRKltujJGiKgxOXXqlNQl1Lvk5GQsXrwYycnJcHJywtixY2vcdUr/MjAwqNXVpboqNjYW7777LjIyMuDm5ob58+dj0aJFUpdVrW7duj3yOMOGxq6xh6ivrrHM/BIkZhbATG6AVnZm2iyZiIhIZ+la1xgHS0ukokWIKZSIiEg6DEJaUJdGNT0dumqMiIiooeja9x6D0COomJ/i/hloa+LfMULarIiIiEi3VXxnVjV3nRQ4WPoRGBgYwNTUFHfu3IGhoWGlifwepLSkDKKsBGVCD0VFhg9/AhERUSOnUqlw584dmJqaqueDk5puVNFIyWQyODk5IT4+vtbTr5eUqZCaWwx9PRlkefU3WIyIiEiX6Onpwc3NrdazpdcXBqFHZGRkhDZt2tS6e+xGej6W/h4Oc2MD7JxV+5mBiYiIGiMjI6Na9aDUNwYhLdDT06v1JYCmJircylXCuEjU6+WDREREVD3diWTNjNyw/NQXlap0bgQ9ERFRc8EgJBFjw39Hy5coVRJWQkRE1HwxCEnE2ODfIFRUyiBEREQkBQYhiRjqy9RzCRWX1s+NXYmIiOjBGIQkIpPJ1K1CbBEiIiKSBoOQhIzvDpguLmOLEBERkRQYhCRUMWCaLUJERETSYBCSkNzg7iX0bBEiIiKSBIOQhCpahIrZIkRERCQJBiEJydVdY2wRIiIikkKzCEJjxoyBlZUVnnnmGalL0cCuMSIiImk1iyD06quv4vvvv5e6jEo4WJqIiEhazSIIDRgwAObm5lKXUYmxAS+fJyIikpLkQejIkSMYMWIEnJ2dIZPJsHPnzkrbhISEwMPDA8bGxggICMCpU6cavtB6wBYhIiIiaUkehPLz8+Hn54eQkJAq12/duhXz5s3DkiVLcPbsWfj5+WHIkCFITU1Vb+Pv748OHTpU+rl9+3ZDHUadqMcIcbA0ERGRJAykLmDYsGEYNmxYtetXr16N6dOnY/LkyQCA9evX488//8S3336LhQsXAgAiIiK0Vk9xcTGKi4vVj3NycrS27/v9e/k8gxAREZEUJG8RepCSkhKcOXMGQUFB6mV6enoICgrC8ePH6+U1V65cCQsLC/WPq6trvbwOcO8tNtg1RkREJAWdDkJpaWlQKpVwcHDQWO7g4IDk5OQa7ycoKAhjx47F7t274eLi8sAQtWjRImRnZ6t/EhMT61z/wxhzHiEiIiJJSd411hAOHjxY423lcjnkcnk9VnPPa6nHCLFFiIiISAo63SJka2sLfX19pKSkaCxPSUmBo6OjRFVpj7pFiJfPExERSUKng5CRkRG6du2K0NBQ9TKVSoXQ0FAEBgbW62uHhITA19cX3bt3r7fXkPNeY0RERJKSvGssLy8PcXFx6sfx8fGIiIiAtbU13NzcMG/ePAQHB6Nbt27o0aMH1qxZg/z8fPVVZPVl1qxZmDVrFnJycmBhYVEvr2HMW2wQERFJSvIgdPr0aQwcOFD9eN68eQCA4OBgbNy4Ec8++yzu3LmDxYsXIzk5Gf7+/ti7d2+lAdSNEW+6SkREJC3Jg9CAAQMghHjgNrNnz8bs2bMbqKKG8+8tNtg1RkREJAWdHiPU1PEWG0RERNJiEKpGgwyWrmgRYtcYERGRJBiEqjFr1ixERUUhPDy83l6DEyoSERFJi0FIQup7jXGMEBERkSQYhCRUca8xtggRERFJg0FIQnKDipml2SJEREQkBQahajTEYOmKFiGlSqBUyTBERETU0BiEqtGQg6UBjhMiIiKSAoOQhCounwc4ToiIiEgKDEISkslkMDLggGkiIiKpMAhJTH3jVc4uTURE1OAYhCT271xCbBEiIiJqaAxC1WiIq8YAQG7IFiEiIiKpMAhVoyGuGgMA47tzCfF+Y0RERA2PQUhi6vuNsWuMiIiowTEISaxiUsVido0RERE1OAYhif17mw22CBERETU0BiGJGXOwNBERkWQYhCQmN+RgaSIiIqkwCFWjoS6fN+Yd6ImIiCTDIFSNhrp8/t95hNgiRERE1NAYhCSmbhHiGCEiIqIGxyAkMfXl87xqjIiIqMExCElMPaEiW4SIiIgaHIOQxEyNyoNQQUmZxJUQERE1PwxCEjOTGwAA8ooYhIiIiBoag5DEzI0NAQC5DEJEREQNjkGoGg01j5CZcXmLUE5Rab2+DhEREVXGIFSNhppHyPxuEMorZosQERFRQ2MQkpjibhBi1xgREVHDYxCSWMUYobziMgghJK6GiIioeWEQkljFVWNKlUBBCSdVJCIiakgMQhIzNdKHvp4MAMcJERERNTQGIYnJZDJ1q1AurxwjIiJqUAxCOqAiCOVwwDQREVGDYhDSAea8coyIiEgSDEI6QFFx5RiDEBERUYNiENIBZsYcI0RERCQFBqFqNNQtNgB2jREREUmFQagaDXWLDeDeIMQWISIioobEIKQDLE2MAABZhQxCREREDYlBSAdYtSgPQpkFDEJEREQNiUFIB1iZll81lplfInElREREzQuDkA6oaBHKYBAiIiJqUAxCOsDa9O4YoQIGISIioobEIKQDrCtahBiEiIiIGhSDkA6wvDtGqKhUhcISpcTVEBERNR8MQjrATG4AQ30ZACCTrUJEREQNhkFIB8hkMliZcsA0ERFRQ2MQ0hHW6rmEGISIiIgaCoOQjqgYJ8RJFYmIiBoOg5COqGgRSs8rlrgSIiKi5oNBSEfYmckBAHdyGYSIiIgaCoNQNUJCQuDr64vu3bs3yOvZK4wBAKkMQkRERA2GQagas2bNQlRUFMLDwxvk9ezM2SJERETU0BiEdIT93SDEFiEiIqKGwyCkI+zNy7vG7uQWSVwJERFR88EgpCPsFeUtQun5JShTqiSuhoiIqHlgENIR1qZGMNCTQQggLY+TKhIRETUEBiEdoacng61ZxTghdo8RERE1BAYhHVLRPZaSwwHTREREDYFBSIc43p1LKCm7UOJKiIiImgcGIR3S0soEAHArk0GIiIioITAI6RAXK1MAwE0GISIiogbBIKRDWlqWtwjdzGIQIiIiaggMQjrEhV1jREREDYpBSIdUtAil5RWjqFQpcTVERERNH4OQDrE0NUQLI30AwC12jxEREdU7BiEdIpPJeOUYERFRA2IQ0jHqAdMMQkRERPWOQUjHqFuEsgokroSIiKjpYxDSMZxLiIiIqOEwCOkYd+vyIHQ9nS1CRERE9Y1BSMe0sjMDAFy7kwchhMTVEBERNW1NPgglJiZiwIAB8PX1RadOnbBt2zapS3ogdxtTyGRAblEZ0vJKpC6HiIioSWvyQcjAwABr1qxBVFQU9u/fj7lz5yI/P1/qsqplbKivnmH62p08iashIiJq2pp8EHJycoK/vz8AwNHREba2tsjIyJC2qIdoZXu3eyxNdwMbERFRUyB5EDpy5AhGjBgBZ2dnyGQy7Ny5s9I2ISEh8PDwgLGxMQICAnDq1Kk6vdaZM2egVCrh6ur6iFXXr1Z2LQCwRYiIiKi+SR6E8vPz4efnh5CQkCrXb926FfPmzcOSJUtw9uxZ+Pn5YciQIUhNTVVv4+/vjw4dOlT6uX37tnqbjIwMvPjii/jqq6/q/Zge1b8DptkiREREVJ8MpC5g2LBhGDZsWLXrV69ejenTp2Py5MkAgPXr1+PPP//Et99+i4ULFwIAIiIiHvgaxcXFGD16NBYuXIhevXo9dNvi4mL145ycnBoeifZ42d5tEWLXGBERUb2SvEXoQUpKSnDmzBkEBQWpl+np6SEoKAjHjx+v0T6EEJg0aRIee+wxvPDCCw/dfuXKlbCwsFD/SNGNVtEilJBRgOIy3oWeiIiovuh0EEpLS4NSqYSDg4PGcgcHByQnJ9doH2FhYdi6dSt27twJf39/+Pv748KFC9Vuv2jRImRnZ6t/EhMTH+kY6sJBIYfC2ABKlcDVVLYKERER1RfJu8bqW58+faBSqWq8vVwuh1wur8eKHk4mk6GdkwKn4jMQnZQDX2eFpPUQERE1VTrdImRrawt9fX2kpKRoLE9JSYGjo6NEVTUMX6fy8BOd1PBjlIiIiJoLnQ5CRkZG6Nq1K0JDQ9XLVCoVQkNDERgYWK+vHRISAl9fX3Tv3r1eX6c6Pk7mAIDLybmSvD4REVFzIHnXWF5eHuLi4tSP4+PjERERAWtra7i5uWHevHkIDg5Gt27d0KNHD6xZswb5+fnqq8jqy6xZszBr1izk5OTAwsKiXl+rKj73tAgJISCTyRq8BiIioqZO8iB0+vRpDBw4UP143rx5AIDg4GBs3LgRzz77LO7cuYPFixcjOTkZ/v7+2Lt3b6UB1E2Nt4M59GRAen4J7uQWw15hLHVJRERETY5M8BbnD1TRIpSdnQ2FomEHLQ/6+BCu3snHxsndMaCtfYO+NhERUWNW0+9vnR4jJCWpxwgBgK9zeZfcpdscME1ERFQfGISqMWvWLERFRSE8PFyyGvxcyoPQuYQsyWogIiJqyhiEdFhnN0sAQERiFtiDSUREpH0MQjqsvbMF9PVkSMsrRlJ2kdTlEBERNTkMQjrM2FAf7RzL5xOKSMySthgiIqImqM5BKC4uDvv27UNhYSEANLmuG10YLA0A/q6WAIBIBiEiIiKtq3UQSk9PR1BQELy9vTF8+HAkJSUBAKZOnYr58+drvUCp6MJgaQDwuxuEziZkSloHERFRU1TrIPTaa6/BwMAACQkJMDU1VS9/9tlnsXfvXq0WR0B3D2sAQGRiNopKlRJXQ0RE1LTUembp/fv3Y9++fXBxcdFY3qZNG9y4cUNrhVE5DxtT2JvLkZpbjHMJWQj0spG6JCIioiaj1i1C+fn5Gi1BFTIyMiCXy7VSFP1LJpOhZ6vy8HPiWrrE1RARETUttQ5Cffv2xffff69+LJPJoFKp8OGHH2rcM4y0J6BVeffYyXgGISIiIm2qddfYhx9+iEGDBuH06dMoKSnBG2+8gUuXLiEjIwNhYWH1UaMkQkJCEBISAqVS+nE5AZ7lLULnErJQXKaE3EBf4oqIiIiahlq3CHXo0AExMTHo06cPRo0ahfz8fDz11FM4d+4cvLy86qNGSejKVWMA4GXXArZmchSXqRCZmC11OURERE1GrVuEAMDCwgJvvfWWtmuhashkMgR4WuPPC0k4cS0dPTytpS6JiIioSah1EDpy5MgD1/fr16/OxVD1erW2wZ8XknAk5g7mDGojdTlERERNQq2D0IABAyotk8lk6n/rwpiapmhAW3sA5RMrZheUwsLUUOKKiIiIGr9ajxHKzMzU+ElNTcXevXvRvXt37N+/vz5qJAAtLU3Qxt4MKgH8E3dH6nKIiIiahFq3CFlYWFRaNnjwYBgZGWHevHk4c+aMVgqjyga0tUNsah4OXbmDJzs5S10OERFRo6e1u887ODjgypUr2tqd5HTlpqv3qugeOxxzBypV07rJLRERkRRkopa3jT9//rzGYyEEkpKS8P7776OsrAxHjx7VaoFSy8nJgYWFBbKzs6FQKCStpbhMic7vHEBBiRK7/tMHHVpWbp0jIiKimn9/17przN/fHzKZDPfnp549e+Lbb7+tfaVUY3IDffRpbYv9USk4EJXCIERERPSIah2E4uPjNR7r6enBzs4OxsbGWiuKqjekvSP2R6Vg78VkvDbYW+pyiIiIGrVaByF3d/f6qINqKMjHAQZ6MlxJycW1O3loZWcmdUlERESNVo2C0GeffVbjHc6ZM6fOxdDDWZgaoldrWxyJuYM9F5Mxa2BrqUsiIiJqtGoUhD755JMa7UwmkzEINYCh7R1xJOYO9jIIERERPZIaBaH7xwWRtB5v74D/23kBF25lIzGjAK7WplKXRERE1ChpbR6hpkYX5xGqYGsmRy8vWwDAr+duSVwNERFR41XreYQA4ObNm/j999+RkJCAkpISjXWrV6/WWnG6QJfmEbrXL2duYv62SHjatsBf8/tr3O+NiIiouau3eYRCQ0MxcuRItGrVCpcvX0aHDh1w/fp1CCHQpUuXRyqaam5oB0f8386LiE/Lx7nELHRxs5K6JCIiokan1l1jixYtwuuvv44LFy7A2NgYv/zyCxITE9G/f3+MHTu2PmqkKrSQG2BYB0cAwI6zNyWuhoiIqHGqdRCKjo7Giy++CAAwMDBAYWEhzMzM8M477+CDDz7QeoFUvae6uAAA/ohMQnGZUuJqiIiIGp9aB6EWLVqoxwU5OTnh6tWr6nVpaWnaq4weKtDLBg4KObILSxEanSp1OURERI1OrYNQz5491TdWHT58OObPn48VK1ZgypQp6Nmzp9YLpOrp68nw9N1WoZ9OJkhcDRERUeNT6yC0evVqBAQEAACWLVuGQYMGYevWrfDw8MD//vc/rRdIDza+hxtkMuBoXBqu3smTuhwiIqJGpU6Xzzcnunr5/L2mbgxH6OVUTOnticUjfKUuh4iISHI1/f6udYvQtGnTcOjQoUepjbTs+cDyG+FuO5OIgpIyiashIiJqPGodhO7cuYOhQ4fC1dUVCxYsQGRkZH3URbXQv40dXK1NkFtUht8jbktdDhERUaNR6yD022+/ISkpCW+//TbCw8PRpUsXtG/fHu+99x6uX79eDyVKQ5dvsXE/PT0Zng8obxXaEFY+uSURERE93COPEbp58yY2b96Mb7/9FrGxsSgra1pdM41hjBAAZBeWotfKUOSXKLFhcncMbGsvdUlERESSqbcxQvcqLS3F6dOncfLkSVy/fh0ODg6Psjt6BBYmhhjfww0A8OXhqw/ZmoiIiIA6BqG///4b06dPh4ODAyZNmgSFQoFdu3bh5k3e6kFKU/p4wkBPhhPXMhCZmCV1OURERDqv1kGoZcuWGD58ONLS0vDVV18hJSUF3377LQYNGsQ7oEvM2dIEI/2dAQBfHmGrEBER0cPU+u7zS5cuxdixY2FpaVkP5dCjmtHPCzvO3sKei8m4kpyLto7mUpdERESks2rdIjR9+nSGIB3W1tEcwzo4QghgzcEYqcshIiLSaY80WJp002uDvSGTAXsuJuPS7WypyyEiItJZDEJNkLeDOUZ0Kh8r9MkBtgoRERFVh0GoiXo1qA30ZMDB6FRE8AoyIiKiKjEINVFedmYY09kFAPDh3sucbZqIiKgKtQ5C3333Hf7880/14zfeeAOWlpbo1asXbty4odXi6NG8NrgNjAz0cOxqOg5Gp0pdDhERkc6pdRB67733YGJiAgA4fvw4QkJC8OGHH8LW1havvfaa1gukunOxMsW0Pp4AgPd2R6OkTCVxRURERLql1kEoMTERrVu3BgDs3LkTTz/9NF566SWsXLkS//zzj9YLpEczc2Br2JrJEZ+Wj++PX5e6HCIiIp1S6yBkZmaG9PR0AMD+/fsxePBgAICxsTEKCwu1Wx09MjO5AV5/3BsA8FloLDLySySuiIiISHfUOggNHjwY06ZNw7Rp0xATE4Phw4cDAC5dugQPDw9t10daMLabK3ycFMgpKsMHey5LXQ4REZHOqHUQCgkJQWBgIO7cuYNffvkFNjY2AIAzZ85g/PjxWi9QKiEhIfD19UX37t2lLuWR6evJsHxUewDA1tOJOBWfIXFFREREukEmeF31A+Xk5MDCwgLZ2dlQKBRSl/NIFv5yHlvCE9HG3gx/zukLIwPOnkBERE1TTb+/a/1NuHfvXhw9elT9OCQkBP7+/pgwYQIyMzPrVi01iIXD2sGmhRFiU/Pw9T/XpC6HiIhIcrUOQgsWLEBOTg4A4MKFC5g/fz6GDx+O+Ph4zJs3T+sFkvZYmhrhrSd8AJQPnL56J0/iioiIiKRV6yAUHx8PX19fAMAvv/yCJ598Eu+99x5CQkKwZ88erRdI2jWmc0v0bWOL4jIV5v8ciTIl5xYiIqLmq9ZByMjICAUFBQCAgwcP4vHHHwcAWFtbq1uKSHfJZDJ88HQnmMsNEJGYhS+PsIuMiIiar1oHoT59+mDevHlYvnw5Tp06hSeeeAIAEBMTAxcXF60XSNrnbGmCJSPLryJbczAG0UkMsERE1DzVOgitXbsWBgYG2L59O9atW4eWLVsCAPbs2YOhQ4dqvUCqH093aYkgHweUKgXm/RzJ228QEVGzxMvnH6IpXT5/v9TcIgz55AgyC0oxtY8n3n7SV+qSiIiItKKm398Gddm5UqnEzp07ER0dDQBo3749Ro4cCX19/bpVS5KwNzfGh8/4Yfr3p/G/o/Ho2coGg30dpC6LiIiowdS6aywuLg4+Pj548cUXsWPHDuzYsQPPP/882rdvj6tXr9ZHjVSPBvs6YOrdO9S/vi0St7J4vzgiImo+ah2E5syZAy8vLyQmJuLs2bM4e/YsEhIS4OnpiTlz5tRHjVTP3hzaDp1cLJBdWIo5m8+hlJfUExFRM1HrMUItWrTAiRMn0LFjR43lkZGR6N27N/LymtYkfU15jNC9EtIL8MRn/yC3uAxTenti8QiOFyIiosar3m6xIZfLkZubW2l5Xl4ejIyMars70hFuNqZYNdYPAPBtWDx+OXNT4oqIiIjqX62D0JNPPomXXnoJJ0+ehBACQgicOHECL7/8MkaOHFkfNVIDGdrBEXMeaw0AWPTrBUQkZklbEBERUT2rdRD67LPP4OXlhcDAQBgbG8PY2Bi9e/dG69at8emnn9ZHjdSA5gZ5I8jHASVlKry86QxSc4ukLomIiKje1HkeodjYWFy+fBkA4OPjg9atW2u1MF3RXMYI3Su3qBRjvjiGuNQ8dHGzxE/Te8LYkFMjEBFR41HT729OqPgQzTEIAcC1O3kYHRKGnKIyDO/oiLXju0BPTyZ1WURERDWi1QkV582bV+MXXr16dY23Jd3Vys4MX77QDS9+exK7LyTjPYto/B9nniYioiamRkHo3LlzNdqZTMYWg6Yk0MsGH431w6tbIvDN0Xi0tDLB5N6eUpdFRESkNTUKQn///Xd911FvsrKyEBQUhLKyMpSVleHVV1/F9OnTpS6r0Rjl3xK3sgrx4d4reGdXFBwUxhje0UnqsoiIiLSiTvcaa0zMzc1x5MgRmJqaIj8/Hx06dMBTTz0FGxsbqUtrNF7p74XbWYX44UQCXt1yDiZG+hjY1l7qsoiIiB5ZrS+fb2z09fVhamoKACguLlbPfUQ1J5PJsGxkBzzZyQmlSoGXN53BiWvpUpdFRET0yCQPQkeOHMGIESPg7OwMmUyGnTt3VtomJCQEHh4eMDY2RkBAAE6dOlWr18jKyoKfnx9cXFywYMEC2Nraaqn65kNfT4ZPnvVHkI89istUmLoxHOcSMqUui4iI6JFIHoTy8/Ph5+eHkJCQKtdv3boV8+bNw5IlS3D27Fn4+flhyJAhSE1NVW/j7++PDh06VPq5ffs2AMDS0hKRkZGIj4/HTz/9hJSUlAY5tqbGUF8Payd0Qe/WNsgvUSL421O4dDtb6rKIiIjqTKfmEZLJZPj1118xevRo9bKAgAB0794da9euBQCoVCq4urriP//5DxYuXFjr15g5cyYee+wxPPPMM1WuLy4uRnFxsfpxTk4OXF1dm908Qg9SUFKGF/53CmduZMLS1BCbpgSgo4uF1GURERGp1dtNVxtSSUkJzpw5g6CgIPUyPT09BAUF4fjx4zXaR0pKivomsdnZ2Thy5Ajatm1b7fYrV66EhYWF+sfV1fXRDqIJMjUywIbJ3dHZzRJZBaWY8M0JnGU3GRERNUI6HYTS0tKgVCrh4OCgsdzBwQHJyck12seNGzfQt29f+Pn5oW/fvvjPf/6Djh07Vrv9okWLkJ2drf5JTEx8pGNoqhTGhtg0NQDdPayQW1SGF745iVPxGVKXRUREVCtN/vL5Hj16ICIiosbby+VyyOXy+iuoCTGTG+C7KT0w7bvTOHY1HcHfnsI3wd3QuzUHoxMRUeOg0y1Ctra20NfXrzS4OSUlBY6OjhJVRfcyNTLAt5O6o5+3HQpLlZi8IRx/nk+SuiwiIqIa0ekgZGRkhK5duyI0NFS9TKVSITQ0FIGBgfX62iEhIfD19UX37t3r9XWaAmNDfXz9YlcM6+CIEqUKszefxXfHrktdFhER0UNJHoTy8vIQERGh7r6Kj49HREQEEhISAJTf8PXrr7/Gd999h+joaLzyyivIz8/H5MmT67WuWbNmISoqCuHh4fX6Ok2F3EAfayd0wQs93SEEsOT3S1i17zInryQiIp0m+Rih06dPY+DAgerHFXe6Dw4OxsaNG/Hss8/izp07WLx4MZKTk+Hv74+9e/dWGkBN0tPXk+GdUe3hoJDjo/0xCPn7KlJzivHeUx1hqC955iYiIqpEp+YR0kU1nYeANG05lYD//noBKgH0bm2DLyZ0hYWpodRlERFRM9Ek5hGSEscIPZrnerjh6xe7oYWRPsLi0jHmizDEp+VLXRYREZEGtgg9BFuEHk10Ug6mfXcat7IKYWFiiHUTu6AXL68nIqJ6xhYh0gk+TgrsnNUbnd0skV1Yihe/PYVNx69zEDUREekEBiGqd3bmcmye3hOj/Z1RphJ4+7dLeH3beRSVKqUujYiImjkGIWoQxob6+ORZfywa1g56MuCXszfx1BfHkJBeIHVpRETUjDEIUYORyWSY0d8LP0wLgE0LI0Ql5WDE2qP4+0qq1KUREVEzxSBUDV41Vn96edli15w+8HctHzc0ZWM4Vu+/gjKlSurSiIiomeFVYw/Bq8bqT3GZEu/uisamEzcAAN3crfDp+M5oaWkicWVERNTY8aox0nlyA30sH90Bn43vDHO5AU7fyMSwNUew9yJv2kpERA2DQYgkN9LPGX/O6Qt/V0vkFJXh5R/O4q1fL/CqMiIiqncMQqQT3GxMse3lQLzc3wsA8OPJBIxcexQXb2VLXBkRETVlDELV4GDphmeor4eFw9ph09QesDOXIyYlD6NDwrDmYAxKOZCaiIjqAQdLPwQHS0sjPa8Y/7fzIvZcTAYAdGipwOpx/vB2MJe4MiIiagw4WJoaNRszOb6Y2AWfPucPCxNDXLyVgyc/O4ovD1+FUsXsTkRE2sEgRDpLJpNhlH9LHHitHx5rZ48SpQor91zG2PXHEJOSK3V5RETUBDAIkc6zVxjjf8Hd8OEznWAmN8DZhCw88dk/+Hj/FV5ZRkREj4RBiBoFmUyGcd1csf+1fgjycUCpUuDzv+Iw7NN/cPxqutTlERFRI8UgRI2Ks6UJvn6xK9ZN7AJ7czni0/Ix/usTeHP7eWQVlEhdHhERNTIMQtXg5fO6SyaTYVhHJxyY1x8TA9wAAFtPJyJo9WFsO50IFQdTExFRDfHy+Yfg5fO6L/x6BhbtuIC41DwAQGc3S7wzsgM6ulhIXBkREUmlpt/fDEIPwSDUOJSUqbAhLB6fhcYiv0QJmQwY38MNCx5vC6sWRlKXR0REDYzzCFGzYmSghxn9vfDX6wMw2t8ZQgA/nUzAgI8OYdOJG5x7iIiIqsQWoYdgi1DjdCo+A4t/u4jLyeXzDbVzNMei4T7o720ncWVERNQQ2DWmJQxCjVeZUoWfTiXg4/0xyC4sBQD087bDf4e3QztH/r8kImrKGIS0hEGo8csqKMHav+Lw3fHrKFUK6MmAsV1dMe9xbzgojKUuj4iI6gGDkJYwCDUdN9Lz8eHeK/jzQhIAwMRQHy/1a4Xp/VrBTG4gcXVERKRNDEJawiDU9Jy5kYkVf0bhbEIWAMC6hRFmDvDC8z3dYWyoL21xRESkFQxCjygkJAQhISFQKpWIiYlhEGpihBDYfSEZH+2/gvi0fACAo8IYcwa1wdhuLjDU5wWVRESNGYOQlrBFqGkrU6rwy9mb+PRgLG5nFwEA3G1M8VqQN0b4OUNfTyZxhUREVBcMQlrCINQ8FJUqsflUAkL+jkNaXvk9y7wdzDA3yBtD2ztCj4GIiKhRYRDSEgah5iW/uAwbj13Hl4evIqeoDEB5IJo1sDWe7MQWIiKixoJBSEsYhJqn7IJS/O/oNWw4dh25dwNRK7sWmD2wNUb6OcOAY4iIiHQag5CWMAg1b9mFpfju2HX872i8elJGdxtTzBrQGmO6tOSgaiIiHcUgpCUMQgQAuUWl2HTiBr75Jx4Z+eVjiFpammB6X0+M6+4KUyPOQ0REpEsYhLSEQYjuVVBShp9OJmD94WtIyysGAFiaGuLFQA8EB7rDxkwucYVERAQwCGkNgxBVpahUie1nbuLrf67hRnoBAEBuoIex3VwwvW8ruNu0kLhCIqLmjUFISxiE6EGUKoF9l5Kx/vBVnL+ZDQDQkwHDOjhhRv9W6ORiKW2BRETNFIOQljAIUU0IIXDiWga+PHIVh67cUS8P8LTG5N6eGOzrwEvviYgaEIPQI+ItNqiuopNy8PWRa/g98jbKVOW/Xi0tTRDcyx3PdnODhamhxBUSETV9DEJawhYhqquk7EJsOn4Dm08lILOg/NJ7E0N9PN21JSb18kRrezOJKyQiaroYhLSEQYgeVVGpEjvP3cKGsOu4kpKrXt63jS2m9PZEf2873sKDiEjLGIS0hEGItEUIgePX0rEh7DoORqeg4jfPw8YUEwLc8ExXV1i3MJK2SCKiJoJBSEsYhKg+JKQX4Pvj17H1dKL6Fh5G+noY3tERE3u6o5u7FWQythIREdUVg5CWMAhRfSooKcPvEbfxw8kbuHgrR728rYM5JvZ0w+jOLaEw5uBqIqLaYhDSEgYhaijnb2bhxxMJ+C3yFopKVQDKB1eP8nfGxAB3dHSxkLhCIqLGg0FISxiEqKFlF5bi17M38ePJBMSm5qmX+zopMK6bC0b5t4QVxxIRET0Qg5CWMAiRVIQQCL+eiR9O3MDei8koUZa3Ehnp6+Hx9g4Y180VvVvbcqJGIqIqMAhpCYMQ6YKsghL8FnEbW8MTEZX071giZwtjPNPVBc90dYWbjamEFRIR6RYGIS1hECJdc/FWNradTsTOiNvILixVLw9sZYNx3V0wtL0TTIz0JayQiEh6DEJawiBEuqqoVIkDUSn4+XQijsalqeclamGkj6EdnPBUl5bo2cqGXWdE1CwxCGkJgxA1BjczC/DLmVvYdiYRNzML1csdFcYY5e+M0Z1bwseJ718iaj4YhLSEQYgaEyEETt/IxK/nbmFX5G3k3J2sEQDaOZpjTOeWGOXfEo4WxhJWSURU/xiEtIRBiBqr4jIl/r6cil/P3cJfl1NRqiz/VZfJgF5eNhjT2QWPt3fghI1E1CQxCD2ikJAQhISEQKlUIiYmhkGIGrWsghL8eSEJO8/dQvj1TPVyIwM9DPC2w5N+zgjysYepkYGEVRIRaQ+DkJawRYiamoT0AvwWcQu/RtzCtTv56uUmhvp4zMceIzo5Y0BbOxgb8sozImq8GIS0hEGImiohBKKTcrHr/G3sOp+EhIwC9TozuQEG+zrgyU5O6NvGDkYGehJWSkRUewxCWsIgRM2BEAIXbmXjj8jb+PN8Em5nF6nXWZgYYkh7BzzZyRmBXjYw1GcoIiLdxyCkJQxC1NyoVALnEjPxR2QSdl9IQmpusXqdhYkhgnwcMLSDI/q2sWX3GRHpLAYhLWEQouZMqRI4FZ+BXedvY9+lZKTllajXmRrpY2A7ewxt74iB7exhJudAayLSHQxCWsIgRFROqRI4fT0Dey8lY9/FZI3uMyMDPfRtbYuhHRwR5OMAqxZGElZKRMQgpDUMQkSVCSFw/mY29l5Kxt6LyYhP+/fqM309GXq2ssbQDk543NcBDgpO3khEDY9BSEsYhIgeTAiBmJQ87L2YjL2XkhGdlKOx3s/FAoN8HBDk4wAfJ3PIZLz3GRHVPwYhLWEQIqqd62n52HcpGXsuJiMiMUtjXUtLEwzysUeQjwMCWllDbsDB1kRUPxiEtIRBiKjuUnOL8Fd0Kg5Gp+Jo3B0UlarU68zkBujvbYdBPvYY2Nae44qISKsYhLSEQYhIOwpLlAiLS8PB6BSEXk7FnXsuy9eTAd08rBF0t7WolZ2ZhJUSUVPAIKQlDEJE2qdSCZy/lY2DUSk4GJ2Cy8m5Gus9bEwxoK09BrS1Q89WNpyviIhqjUFISxiEiOpfYkYBQqNTcDA6FSfj01Gq/PdjydhQD4GtbDCgbXkXmpuNqYSVElFjwSCkJQxCRA0rr7gMYXFpOHQlFYeu3EHSPfMVAUAruxYY4G2Pge3s0MOTA66JqGoMQlrCIEQkHSEErqTk4tCVO/j7cirO3MhEmerfjywTQ330bm2D/m3tMcDbDq7WbC0ionIMQlrCIESkO3KKShEWm1YejK6katwHDShvLerb2hZ929ihp5cNb/tB1IwxCGkJgxCRbhJCIDopF39fScXhK3dwJiETyntaiwz0ZOjiZoW+bWzRp40tOrlYQl+PkzkSNRcMQlrCIETUOOQUleL41XQcjU3DP7F3cD29QGO9hYkhennZoG8bO/RtY8tuNKImjkFISxiEiBqnxIwC/HM3FIXFpSGnqExjvYeNKfq2sUOfNrYI9LKBwthQokqJqD4wCN2noKAAPj4+GDt2LD766KMaP49BiKjxU6oEzt/Mwj+xaTgam4azCZqDrvX1ZOjkYoFeXjbo5WWLru5WnLuIqJFjELrPW2+9hbi4OLi6ujIIETVzuUWlOHEtA0dj7+Cf2DRcS8vXWG+kr4cu7pbo5WWLXl426ORiCSMDPYmqJaK6qOn3d7O4pCI2NhaXL1/GiBEjcPHiRanLISKJmRsbYrCvAwb7OgAAbmUV4vjVdBy7moZjcelIzinCiWsZOHEtA6sPAKZG+ujuYa1uMfJ1VnDgNVETIfmfOEeOHMGIESPg7OwMmUyGnTt3VtomJCQEHh4eMDY2RkBAAE6dOlWr13j99dexcuVKLVVMRE1NS0sTPNPVBavH+eP4osfw9+sDsGJMBzzRyQnWLYxQUKLE4Zg7WLnnMkasPYrO7+zHS9+fxsaweMSk5KKZNKwTNUmStwjl5+fDz88PU6ZMwVNPPVVp/datWzFv3jysX78eAQEBWLNmDYYMGYIrV67A3t4eAODv74+ysrJKz92/fz/Cw8Ph7e0Nb29vHDt2rN6Ph4gaN5lMBk/bFvC0bYGJAe5QqQRiUnNxLC4dx66m4+S1dOQUlWF/VAr2R6UAAGzNjNDD0xo9PKwR0MoGbR3MoccWI6JGQafGCMlkMvz6668YPXq0ellAQAC6d++OtWvXAgBUKhVcXV3xn//8BwsXLnzoPhctWoQffvgB+vr6yMvLQ2lpKebPn4/FixdXuX1xcTGKi/+dpC0nJweurq4cI0REAIAypQqXbufg2N2utPDrGSgqVWlsY2FiiO4e1ujZyhoBnjbwcTKHgb7kDfBEzUqjHCx9fxAqKSmBqakptm/frhGOgoODkZWVhd9++61W+9+4cSMuXrz4wMHSS5cuxbJlyyotZxAioqoUlylx/mY2TsVn4MS1dJy5kYmCEqXGNmZyA3TzsEIPz/Jg1MnFAoYMRkT1qkkMlk5LS4NSqYSDg4PGcgcHB1y+fLleXnPRokWYN2+e+nFFixARUVXkBuUDqbt7WGPWwNYovdtidPJaOk7FZ+DU9QzkFpXh0JU7OHTlDoDye6R1cbdEgKcNenhaw9/VkpfrE0lEp4OQtk2aNOmh28jlcsjl8vovhoiaJEN9Pfi7WsLf1RIz+ntBqRKITsrBqfgMnIwvD0eZBaUIi0tHWFw6AMDIQA/+Lpbo5mGF7h7W6OJmBQtTTvBI1BB0OgjZ2tpCX18fKSkpGstTUlLg6OgoUVVERDWnrydDh5YW6NDSAlP6eEKlEoi7k4eT19JxMj4DJ+MzcCe3GKeul7ceAVcBAN4OZujmYY1u7uXhyMXKBDIZB2ATaZtOByEjIyN07doVoaGh6jFCKpUKoaGhmD17dr2+dkhICEJCQqBUKh++MRFRDenpyeDtYA5vB3O8EOgBIQTi0/IRfj0Dp69n4vSNTMSn5SMmJQ8xKXn46WQCAMDeXI7uHtbo6m6Fbh5W8HVScAA2kRZIPlg6Ly8PcXFxAIDOnTtj9erVGDhwIKytreHm5oatW7ciODgYX375JXr06IE1a9bg559/xuXLlyuNHaoPnFmaiBpaWl4xTl/PxJkbGTh9IxMXb2WjVKn5UW1qpA9/V0t1q1FnN0uY835pRGqN5qqxQ4cOYeDAgZWWBwcHY+PGjQCAtWvXYtWqVUhOToa/vz8+++wzBAQENEh9DEJEJLWiUiUiE7Nw+kYmTl/PwJkbmZVuIqsnA9o5KtDNwwpd3a3Qxc2K3WnUrDWaIKTrGISISNeoVAKxqXk4faOiOy0DiRmFlbazNTOCv6sVurhborOrFTq5WKCFXKdHRBBpDYOQljAIEVFjkJJTpA5FZxOyEHW7cndaRatRZzdLdHazQhc3S3jatmCrETVJDEKP6N7B0jExMQxCRNSoFJUqcel2Ns4lZOFcQhbOJmQiKbuo0naWpobwd7VEF7fycUZ+rpZQcKwRNQEMQlrCFiEiaiqSsgsRcTcUnUvIwvlb2Sgp07w9iEwGtLE3Q2fX8mDUxd0KXnZm0Oe906iRYRDSEgYhImqqSspUiE7KwbmETJxLLA9IVY01amGkj44uFvBzKW8x8nO1hLOFMbvUSKcxCGkJgxARNSd3cosRkVjRapSJyMRsFJZWnk/N1swIfi6W6ORiCT/X8pBk1cJIgoqJqsYgpCUMQkTUnJUpVYi7k4fIxCxE3sxGZGIWriTnokxV+avDzdq0vMXIxQJ+rpZo76yAqRGvUiNpMAg9Ig6WJiKqWvlA7BxEJmbh/M3ygBSfll9pOz0Z4O1gDn/Xf1uOvB3MYcgZsakBMAhpCVuEiIgeLrugFOdvZWm0HKXmFlfaTm6ghw4tLdDx7v3XOra0gJddC94uhLSOQUhLGISIiOomObsIEepWoyycv5mN3PtmxAYAY0M9+Dop/g1HLhZobWfGcESPhEFISxiEiIi0Q6USiE/Px/mbWbhwMwcXb2Xj0u1s5JdUHoxtbKgHn3vDUUsLtLFnOKKaYxDSEgYhIqL6o1QJxKfl4+KtbFy4+3PpVtXhSG7wbziqCEhtHMw45oiqxCCkJQxCREQNq6Ll6OKtbFy4eTcc3c5BXnHlbjWju+Gog3N5QGrvXB6OjA31JaicdAmD0CPiVWNERLpDpRK4np6PC7ey1a1Hl27lILeKcGSgJ0NrezP4Oing66xAe2cL+DopYGHKW4c0JwxCWsIWISIi3aRSCdzIKFCHo0u3y1uOsgpKq9zexcoEvk53g5GzAu2dFXDiDNlNFoOQljAIERE1HkIIJGUX4dLtHETdzsGl29mISsrBzczKtw4BACtTQ/g6K9QBqb2zAp62vJy/KWAQ0hIGISKixi+7oBSXkrIRdTcgRSXlIDY1D8oqZsiWG+ihnVNFOCrvXvNxVMDEiOOOGhMGIS1hECIiapqKSpWITclTtxpdup2D6KQcFFRxxZqeDPC0bQEfJ8XdH3O0c2TXmi5jENISBiEiouZDqRK4kZ5f3rV2NxxF3c5GWl5JldsrjA3UrUftHM3RzkkBbwcz3mNNBzAIaQmDEBERpeYU4VJSDi4n5eJycvl/r97Jq/LmszIZ4GnTAu3uthq1czSHj5MCLlYmbD1qQAxCj4iXzxMR0YMUlykRl5r3bzhKzkV0Uk61rUfmcgO0dTRXByQfJwXaOprDTM7Wo/rAIKQlbBEiIqLauJNbrG41ik7OQXRSLuJSc1GqrPrr1s3aVN1q5ONkjraOCrhZm0Jfj61Hj4JBSEsYhIiI6FGVKlW4dicfl+8Go+ikHFxOzkFKTnGV2xsb6qGNvTm8HczR1tHs7n/N4ajg4OyaYhDSEgYhIiKqLxn5Jf+2HiWVd6/FpOSiuExV5fbmxgZo62AOb0dztHO8G5QczGHVwqiBK9d9DEJawiBEREQNSakSSMgowJW7oehKSi5iknNxLS2/ynmPAMDOXF4ekO5pQWrj0LzHHzEIaQmDEBER6YLiMiWu3ckvD0f3hKTEjKpnzQbKbytS0YJUEZS87FtAbtD0J4dkENISBiEiItJl+cVliE3NQ0zy3daju0EpNbfq8Uf6ejJ42Jii7d2utTb25mjjYAYPmxYwMmg6txZhENISBiEiImqMMvNLEJNyb/daHi4n5yCnqKzK7SsCUkUwam1vhjb25mhl1wLGho2vBYlB6BFxHiEiImpqhBBIySlWjzuKTc1FbGoe4lLykFtcdUDSkwHuNi3uBiMztHEoD0hedmY6ff81BiEtYYsQERE1dRUBKTY1FzEpeYhLzUVsSh5iUnKrbUGSycrHILWxN78bkMr/62VvphODtBmEtIRBiIiImishBO7kFSMuJQ+xqXnlLUgpeYhLzUN6ftUzaANAS0sTjRak1vbmaG1vBgsTwwarnUFISxiEiIiIKkvPK74bjvIQl5Kr/vedagZpA4CDQo7W9mZobVc+BsnLvvy/dmZyrU8UySCkJQxCRERENZdVUIK4u6EoNqW8FSkuNQ9J2UXVPufz8Z0xws9Zq3XU9Ptb+k48IiIiajIsTY3QzcMa3TysNZbnFJUiLrW8W+3q3f/G3clDQkYBPG1bSFQtgxARERE1AIWxIbq4WaGLm5XG8qJSJQz1pZu/iEGIiIiIJCP1HEVNZwpJIiIiolpiECIiIqJmi0GIiIiImi0GoWqEhITA19cX3bt3l7oUIiIiqiecR+ghOI8QERFR41PT72+2CBEREVGzxSBEREREzRaDEBERETVbDEJERETUbDEIERERUbPFIERERETNFoMQERERNVsMQkRERNRs8e7zD1Ex32ROTo7ElRAREVFNVXxvP2zeaAahh8jNzQUAuLq6SlwJERER1VZubi4sLCyqXc9bbDyESqXC7du3YW5uDplMprX95uTkwNXVFYmJibx1Rz3juW4YPM8Ng+e5YfA8N5z6OtdCCOTm5sLZ2Rl6etWPBGKL0EPo6enBxcWl3vavUCj4S9ZAeK4bBs9zw+B5bhg8zw2nPs71g1qCKnCwNBERETVbDEJERETUbDEISUQul2PJkiWQy+VSl9Lk8Vw3DJ7nhsHz3DB4nhuO1Oeag6WJiIio2WKLEBERETVbDEJERETUbDEIERERUbPFIERERETNFoOQREJCQuDh4QFjY2MEBATg1KlTUpfUaKxcuRLdu3eHubk57O3tMXr0aFy5ckVjm6KiIsyaNQs2NjYwMzPD008/jZSUFI1tEhIS8MQTT8DU1BT29vZYsGABysrKGvJQGpX3338fMpkMc+fOVS/jedaeW7du4fnnn4eNjQ1MTEzQsWNHnD59Wr1eCIHFixfDyckJJiYmCAoKQmxsrMY+MjIyMHHiRCgUClhaWmLq1KnIy8tr6EPRWUqlEm+//TY8PT1hYmICLy8vLF++XONeVDzPdXPkyBGMGDECzs7OkMlk2Llzp8Z6bZ3X8+fPo2/fvjA2Noarqys+/PDDRy9eUIPbsmWLMDIyEt9++624dOmSmD59urC0tBQpKSlSl9YoDBkyRGzYsEFcvHhRREREiOHDhws3NzeRl5en3ubll18Wrq6uIjQ0VJw+fVr07NlT9OrVS72+rKxMdOjQQQQFBYlz586J3bt3C1tbW7Fo0SIpDknnnTp1Snh4eIhOnTqJV199Vb2c51k7MjIyhLu7u5g0aZI4efKkuHbtmti3b5+Ii4tTb/P+++8LCwsLsXPnThEZGSlGjhwpPD09RWFhoXqboUOHCj8/P3HixAnxzz//iNatW4vx48dLcUg6acWKFcLGxkbs2rVLxMfHi23btgkzMzPx6aefqrfhea6b3bt3i7feekvs2LFDABC//vqrxnptnNfs7Gzh4OAgJk6cKC5evCg2b94sTExMxJdffvlItTMISaBHjx5i1qxZ6sdKpVI4OzuLlStXSlhV45WamioAiMOHDwshhMjKyhKGhoZi27Zt6m2io6MFAHH8+HEhRPkvrZ6enkhOTlZvs27dOqFQKERxcXHDHoCOy83NFW3atBEHDhwQ/fv3VwchnmftefPNN0WfPn2qXa9SqYSjo6NYtWqVellWVpaQy+Vi8+bNQgghoqKiBAARHh6u3mbPnj1CJpOJW7du1V/xjcgTTzwhpkyZorHsqaeeEhMnThRC8Dxry/1BSFvn9YsvvhBWVlYanx1vvvmmaNu27SPVy66xBlZSUoIzZ84gKChIvUxPTw9BQUE4fvy4hJU1XtnZ2QAAa2trAMCZM2dQWlqqcY7btWsHNzc39Tk+fvw4OnbsCAcHB/U2Q4YMQU5ODi5dutSA1eu+WbNm4YknntA4nwDPszb9/vvv6NatG8aOHQt7e3t07twZX3/9tXp9fHw8kpOTNc61hYUFAgICNM61paUlunXrpt4mKCgIenp6OHnyZMMdjA7r1asXQkNDERMTAwCIjIzE0aNHMWzYMAA8z/VFW+f1+PHj6NevH4yMjNTbDBkyBFeuXEFmZmad6+NNVxtYWloalEqlxhcDADg4OODy5csSVdV4qVQqzJ07F71790aHDh0AAMnJyTAyMoKlpaXGtg4ODkhOTlZvU9X/g4p1VG7Lli04e/YswsPDK63jedaea9euYd26dZg3bx7++9//Ijw8HHPmzIGRkRGCg4PV56qqc3nvuba3t9dYb2BgAGtra57ruxYuXIicnBy0a9cO+vr6UCqVWLFiBSZOnAgAPM/1RFvnNTk5GZ6enpX2UbHOysqqTvUxCFGjNmvWLFy8eBFHjx6VupQmJzExEa+++ioOHDgAY2Njqctp0lQqFbp164b33nsPANC5c2dcvHgR69evR3BwsMTVNR0///wzfvzxR/z0009o3749IiIiMHfuXDg7O/M8N2PsGmtgtra20NfXr3RlTUpKChwdHSWqqnGaPXs2du3ahb///hsuLi7q5Y6OjigpKUFWVpbG9veeY0dHxyr/H1Sso/Kur9TUVHTp0gUGBgYwMDDA4cOH8dlnn8HAwAAODg48z1ri5OQEX19fjWU+Pj5ISEgA8O+5etDnhqOjI1JTUzXWl5WVISMjg+f6rgULFmDhwoV47rnn0LFjR7zwwgt47bXXsHLlSgA8z/VFW+e1vj5PGIQamJGREbp27YrQ0FD1MpVKhdDQUAQGBkpYWeMhhMDs2bPx66+/4q+//qrUVNq1a1cYGhpqnOMrV64gISFBfY4DAwNx4cIFjV+8AwcOQKFQVPpCaq4GDRqECxcuICIiQv3TrVs3TJw4Uf1vnmft6N27d6UpIGJiYuDu7g4A8PT0hKOjo8a5zsnJwcmTJzXOdVZWFs6cOaPe5q+//oJKpUJAQEADHIXuKygogJ6e5teevr4+VCoVAJ7n+qKt8xoYGIgjR46gtLRUvc2BAwfQtm3bOneLAeDl81LYsmWLkMvlYuPGjSIqKkq89NJLwtLSUuPKGqreK6+8IiwsLMShQ4dEUlKS+qegoEC9zcsvvyzc3NzEX3/9JU6fPi0CAwNFYGCgen3FZd2PP/64iIiIEHv37hV2dna8rPsh7r1qTAieZ205deqUMDAwECtWrBCxsbHixx9/FKampuKHH35Qb/P+++8LS0tL8dtvv4nz58+LUaNGVXn5cefOncXJkyfF0aNHRZs2bZr9Zd33Cg4OFi1btlRfPr9jxw5ha2sr3njjDfU2PM91k5ubK86dOyfOnTsnAIjVq1eLc+fOiRs3bgghtHNes7KyhIODg3jhhRfExYsXxZYtW4SpqSkvn2+sPv/8c+Hm5iaMjIxEjx49xIkTJ6QuqdEAUOXPhg0b1NsUFhaKmTNnCisrK2FqairGjBkjkpKSNPZz/fp1MWzYMGFiYiJsbW3F/PnzRWlpaQMfTeNyfxDiedaeP/74Q3To0EHI5XLRrl078dVXX2msV6lU4u233xYODg5CLpeLQYMGiStXrmhsk56eLsaPHy/MzMyEQqEQkydPFrm5uQ15GDotJydHvPrqq8LNzU0YGxuLVq1aibfeekvjcmye57r5+++/q/xcDg4OFkJo77xGRkaKPn36CLlcLlq2bCnef//9R65dJsQ9U2oSERERNSMcI0RERETNFoMQERERNVsMQkRERNRsMQgRERFRs8UgRERERM0WgxARERE1WwxCRERE1GwxCBERNRAPDw+sWbNG6jKI6B4MQkQkiUmTJkEmk+H999/XWL5z507IZDKJqiKi5oZBiIgkY2xsjA8++ACZmZlSl0JEzRSDEBFJJigoCI6Ojli5cuUDt/vll1/Qvn17yOVyeHh44OOPP671ax09ehR9+/aFiYkJXF1dMWfOHOTn56vXe3h4YPny5Rg/fjxatGiBli1bIiQkRGMfCQkJGDVqFMzMzKBQKDBu3DikpKRobPPHH3+ge/fuMDY2hq2tLcaMGaOxvqCgAFOmTIG5uTnc3Nzw1Vdf1fpYiEh7GISISDL6+vp477338Pnnn+PmzZtVbnPmzBmMGzcOzz33HC5cuIClS5fi7bffxsaNG2v8OlevXsXQoUPx9NNP4/z589i6dSuOHj2K2bNna2y3atUq+Pn54dy5c1i4cCFeffVVHDhwAACgUqkwatQoZGRk4PDhwzhw4ACuXbuGZ599Vv38P//8E2PGjMHw4cNx7tw5hIaGokePHhqv8fHHH6Nbt244d+4cZs6ciVdeeQVXrlyp8bEQkZY98m1biYjqIDg4WIwaNUoIIUTPnj3FlClThBBC/Prrr+Lej6YJEyaIwYMHazx3wYIFwtfXt8avNXXqVPHSSy9pLPvnn3+Enp6eKCwsFEII4e7uLoYOHaqxzbPPPiuGDRsmhBBi//79Ql9fXyQkJKjXX7p0SQAQp06dEkIIERgYKCZOnFhtHe7u7uL5559XP1apVMLe3l6sW7euxsdCRNrFFiEiktwHH3yA7777DtHR0ZXWRUdHo3fv3hrLevfujdjYWCiVyhrtPzIyEhs3boSZmZn6Z8iQIVCpVIiPj1dvFxgYqPG8wMBAdU3R0dFwdXWFq6urer2vry8sLS3V20RERGDQoEEPrKVTp07qf8tkMjg6OiI1NbVGx0FE2mcgdQFERP369cOQIUOwaNEiTJo0Sev7z8vLw4wZMzBnzpxK69zc3LT2OiYmJg/dxtDQUOOxTCaDSqXSWg1EVDsMQkSkE95//334+/ujbdu2Gst9fHwQFhamsSwsLAze3t7Q19ev0b67dOmCqKgotG7d+oHbnThxotJjHx8fdR2JiYlITExUtwpFRUUhKysLvr6+AMpbe0JDQzF58uQa1UVE0mPXGBHphI4dO2LixIn47LPPNJbPnz8foaGhWL58OWJiYvDdd99h7dq1eP3119XbDBo0CGvXrq1232+++SaOHTuG2bNnIyIiArGxsfjtt98qDZYOCwvDhx9+iJiYGISEhGDbtm149dVXAZRf4VZR49mzZ3Hq1Cm8+OKL6N+/P7p16wYAWLJkCTZv3owlS5YgOjoaFy5cwAcffKCtU0RE9YBBiIh0xjvvvFOpm6hLly74+eefsWXLFnTo0AGLFy/GO++8o9GFdvXqVaSlpVW7306dOuHw4cOIiYlB37590blzZyxevBjOzs4a282fPx+nT59G586d8e6772L16tUYMmQIgPIurN9++w1WVlbo168fgoKC0KpVK2zdulX9/AEDBmDbtm34/fff4e/vj8ceewynTp3SwpkhovoiE0IIqYsgIpKah4cH5s6di7lz50pdChE1ILYIERERUbPFIERERETNFrvGiIiIqNliixARERE1WwxCRERE1GwxCBEREVGzxSBEREREzRaDEBERETVbDEJERETUbDEIERERUbPFIERERETNFoMQERERNVv/D4I02WzA6HVtAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matt_model.trainable_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SsJM-B889Ka",
        "outputId": "982aecc3-f453-4ab6-ad0b-4f4e280db94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'layer1/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[0.37851793, 0.47730803],\n",
              "        [0.65703505, 0.7546152 ]], dtype=float32)>,\n",
              " <tf.Variable 'layer1/bias:0' shape=(2,) dtype=float32, numpy=array([0.35, 0.35], dtype=float32)>,\n",
              " <tf.Variable 'layer2/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[-3.8930314,  2.86187  ],\n",
              "        [-3.868474 ,  2.9257443]], dtype=float32)>,\n",
              " <tf.Variable 'layer2/bias:0' shape=(2,) dtype=float32, numpy=array([0.6, 0.6], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let see the results\n",
        "matt_model(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGC6UeWAvPyx",
        "outputId": "9ca7b902-fe93-4b56-e9be-efba2460afe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.01591251, 0.9840654 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matt Model : See the gradients\n",
        " We create a Custom training loop to see/update the gradients during training using GradientTape()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t2sxO1umvaK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mattews inputs\n",
        "#inputs = tf.constant([[0.05, 0.1]])\n",
        "#batch_input=np.vstack([inputs]*2)\n",
        "\n",
        "#W1 = np.array([[0.15,0.25],[0.2,0.3]]) # we initialize the weights according to Mattews example\n",
        "#b1 = np.array([0.35,0.35])             # we initialize biases according to Mattews example\n",
        "#setBias1=SetBias(0.35)\n",
        "#\n",
        "\n",
        "#W2 = np.array([[0.4,0.5],[0.45,0.55]])\n",
        "#b2 = np.array([0.6,0.6])\n",
        "#setBias2=SetBias(0.6)\n",
        "\n",
        "#Let's reset the layers\n",
        "dense_layer1 = layers.Dense(units=2,\n",
        "                            use_bias=True,\n",
        "                            bias_constraint=setBias1,\n",
        "                            weights = [W1,b1],\n",
        "                            activation=activations.sigmoid,\n",
        "                            name='layer1'\n",
        "                            )\n",
        "\n",
        "dense_layer2 = layers.Dense(units=2,\n",
        "                            use_bias=True,\n",
        "                            bias_constraint=setBias2,\n",
        "                            weights = [W2,b2],\n",
        "                            activation=activations.sigmoid,\n",
        "                            name='layer2'\n",
        "                            )\n",
        "layer_inputs = Input(shape=(2,))\n",
        "out_layer1=dense_layer1(layer_inputs)\n",
        "out_layer2=dense_layer2(out_layer1)\n",
        "matt_model=Model(layer_inputs,out_layer2)\n",
        "matt_model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=optimizers.legacy.SGD(learning_rate=0.5), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "WhTzoSLq0uX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#x_tr = tf.constant([[0.05, 0.1],[0.05, 0.1]])\n",
        "#y_tr = tf.constant([[0.01, 0.99],[0.01, 0.99]])\n",
        "x_tr = tf.constant([[0.05, 0.1]])\n",
        "y_tr = tf.constant([[0.01, 0.99]])\n",
        "\n",
        "xdataset = tf.data.Dataset.from_tensor_slices([x_tr])\n",
        "ydataset = tf.data.Dataset.from_tensor_slices([y_tr])\n",
        "tr_dataset = tf.data.Dataset.zip(xdataset, ydataset)\n",
        "\n",
        "\n",
        "loss_fn=tf.keras.losses.MeanSquaredError()\n",
        "optimizer_leg = tf.keras.optimizers.legacy.SGD(learning_rate=0.5)\n",
        "\n",
        "for (x, y_true) in tr_dataset:\n",
        "    # Open a GradientTape.\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass.\n",
        "        y_pred = matt_model(x)\n",
        "        # Loss value for this batch of 1 input\n",
        "        loss = loss_fn( y_true,y_pred)\n",
        "\n",
        "    # Get gradients of the loss wrt the weights.\n",
        "    gradients = tape.gradient(loss, matt_model.trainable_weights)\n",
        "    trainable_weights=matt_model.trainable_weights\n",
        "    #Update the weights of our linear layer.\n",
        "    optimizer_leg.apply_gradients(zip(gradients, matt_model.trainable_weights))\n",
        "\n",
        "    # Logging.\n",
        "    print( f'gradients {gradients}, \\n      Loss : {float(loss)}')\n",
        "    # Loss should be about 0.29837111 after 1 backpropagation\n",
        "    # Loss should be about 0.29102792 after 2 backpropagation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwB3T5BUBV1h",
        "outputId": "552f1ab4-ac61-434d-b261-426f6b2862dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gradients [<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "array([[0.00043857, 0.00049771],\n",
            "       [0.00087714, 0.00099543]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.00877136, 0.00995425], dtype=float32)>, <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "array([[ 0.08216704, -0.02260254],\n",
            "       [ 0.08266763, -0.02274024]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 0.13849856, -0.03809823], dtype=float32)>], \n",
            "      Loss : 0.2983711063861847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matt_model.trainable_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eIwdHK9B6su",
        "outputId": "cf580c72-ddfb-4d26-f19e-497546c4da86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'layer1/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[0.14978072, 0.24975115],\n",
              "        [0.19956143, 0.2995023 ]], dtype=float32)>,\n",
              " <tf.Variable 'layer1/bias:0' shape=(2,) dtype=float32, numpy=array([0.6, 0.6], dtype=float32)>,\n",
              " <tf.Variable 'layer2/kernel:0' shape=(2, 2) dtype=float32, numpy=\n",
              " array([[0.3589165 , 0.5113013 ],\n",
              "        [0.40866616, 0.56137013]], dtype=float32)>,\n",
              " <tf.Variable 'layer2/bias:0' shape=(2,) dtype=float32, numpy=array([0.6, 0.6], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    }
  ]
}